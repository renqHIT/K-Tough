Changing view acls to: renq
Changing modify acls to: renq
SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(renq); users with modify permissions: Set(renq)
In createActorSystem, requireCookie is: off
Slf4jLogger started
Starting remoting
Remoting started; listening on addresses :[akka.tcp://sparkDriver@cluster01:34388]
Remoting now listens on addresses: [akka.tcp://sparkDriver@cluster01:34388]
Successfully started service 'sparkDriver' on port 34388.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
Registering BlockManagerMaster
[actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#31969857]
[actor] handled message (1.403184 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#31969857]
Getting/creating local root dirs at '/tmp'
Created local directory at /tmp/spark-local-20150123125145-16fb
Using SLF4J as the default logging framework
-Dio.netty.leakDetectionLevel: simple
java.nio.Buffer.address: available
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Bits.unaligned: true
UID: 1002
Java version: 7
-Dio.netty.noUnsafe: false
sun.misc.Unsafe: available
-Dio.netty.noJavassist: false
Javassist: unavailable
You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
Successfully started service 'Connection manager for block manager' on port 44766.
Bound socket to port 44766 with id = ConnectionManagerId(cluster01,44766)
MemoryStore started with capacity 3.6 GB
Trying to register BlockManager
[actor] received message RegisterBlockManager(BlockManagerId(<driver>, cluster01, 44766, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-372687943]) from Actor[akka://sparkDriver/temp/$a]
Registering block manager cluster01:44766 with 3.6 GB RAM, BlockManagerId(<driver>, cluster01, 44766, 0)
[actor] handled message (1.96327 ms) RegisterBlockManager(BlockManagerId(<driver>, cluster01, 44766, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-372687943]) from Actor[akka://sparkDriver/temp/$a]
Registered BlockManager
HTTP File server directory is /tmp/spark-ec65adc7-d85f-4cca-b609-28ae64d52fb0
Starting HTTP Server
HttpServer is not using security
Successfully started service 'HTTP file server' on port 46030.
HTTP file server started at: http://192.168.2.1:46030
Successfully started service 'SparkUI' on port 4040.
Started SparkUI at http://cluster01:4040
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:265)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:290)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
	at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:283)
	at org.apache.spark.deploy.SparkHadoopUtil.<init>(SparkHadoopUtil.scala:36)
	at org.apache.spark.deploy.SparkHadoopUtil$.<init>(SparkHadoopUtil.scala:109)
	at org.apache.spark.deploy.SparkHadoopUtil$.<clinit>(SparkHadoopUtil.scala)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:238)
	at Toughness$.main(toughness.scala:12)
	at Toughness.main(toughness.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:329)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
setsid exited with exit code 0
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
Added JAR file:/home/renq/k-tough/target/scala-2.10/toughness_2.10-1.0.jar at http://192.168.2.1:46030/jars/toughness_2.10-1.0.jar with timestamp 1421988706150
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] handled message (9.973659 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
Connecting to master spark://cluster01:7077...
SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
ensureFreeSpace(163705) called with curMem=0, maxMem=3890007244
Block broadcast_0 stored as values in memory (estimated size 159.9 KB, free 3.6 GB)
Put block broadcast_0 locally took  162 ms
Putting block broadcast_0 without replication took  163 ms
[actor] received message RegisteredApplication(app-20150123125146-0005,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Connected to Spark cluster with app ID app-20150123125146-0005
[actor] handled message (0.868171 ms) RegisteredApplication(app-20150123125146-0005,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150123125146-0005/0 on worker-20150121184032-cluster02-48233 (cluster02:48233) with 2 cores
Granted executor ID app-20150123125146-0005/0 on hostPort cluster02:48233 with 2 cores, 6.0 GB RAM
[actor] handled message (1.366775 ms) ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150123125146-0005/1 on worker-20150121184029-cluster01-58596 (cluster01:58596) with 2 cores
Granted executor ID app-20150123125146-0005/1 on hostPort cluster01:58596 with 2 cores, 6.0 GB RAM
[actor] handled message (0.415977 ms) ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150123125146-0005/2 on worker-20150121184032-cluster03-48380 (cluster03:48380) with 2 cores
Granted executor ID app-20150123125146-0005/2 on hostPort cluster03:48380 with 2 cores, 6.0 GB RAM
[actor] handled message (0.452134 ms) ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150123125146-0005/0 is now LOADING
[actor] handled message (0.992603 ms) ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150123125146-0005/2 is now LOADING
[actor] handled message (0.181921 ms) ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150123125146-0005/1 is now LOADING
[actor] handled message (0.191553 ms) ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
ensureFreeSpace(12633) called with curMem=163705, maxMem=3890007244
Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.3 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Added broadcast_0_piece0 in memory on cluster01:44766 (size: 12.3 KB, free: 3.6 GB)
[actor] handled message (1.163253 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  7 ms
Putting block broadcast_0_piece0 without replication took  7 ms
Creating new JobConf and caching it for later re-use
hadoop login
hadoop login commit
using local user:UnixPrincipal: renq
UGI loginUser:renq (auth:SIMPLE)
Time taken to get FileStatuses: 4
Total input paths to process : 1
Total # of splits generated by getSplits: 3, TimeTaken: 9
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6bddea9) from Actor[akka://sparkDriver/temp/$c]
[actor] handled message (0.568825 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6bddea9) from Actor[akka://sparkDriver/temp/$c]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ddc63f6) from Actor[akka://sparkDriver/temp/$d]
[actor] handled message (0.167582 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ddc63f6) from Actor[akka://sparkDriver/temp/$d]
Starting job: count at GraphLoader.scala:87
Got job 0 (count at GraphLoader.scala:87) with 1 output partitions (allowLocal=false)
Final stage: Stage 0(count at GraphLoader.scala:87)
Parents of final stage: List()
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@ebc21da) from Actor[akka://sparkDriver/temp/$e]
[actor] handled message (0.135143 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@ebc21da) from Actor[akka://sparkDriver/temp/$e]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@728b5f94) from Actor[akka://sparkDriver/temp/$f]
[actor] handled message (0.140583 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@728b5f94) from Actor[akka://sparkDriver/temp/$f]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1c30284c) from Actor[akka://sparkDriver/temp/$g]
[actor] handled message (0.133402 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1c30284c) from Actor[akka://sparkDriver/temp/$g]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1da5a409) from Actor[akka://sparkDriver/temp/$h]
[actor] handled message (0.132155 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1da5a409) from Actor[akka://sparkDriver/temp/$h]
Missing parents: List()
submitStage(Stage 0)
missing: List()
Submitting Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68), which has no missing parents
submitMissingTasks(Stage 0)
ensureFreeSpace(3120) called with curMem=176338, maxMem=3890007244
Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 3.6 GB)
Put block broadcast_1 locally took  2 ms
Putting block broadcast_1 without replication took  2 ms
ensureFreeSpace(1887) called with curMem=179458, maxMem=3890007244
Block broadcast_1_piece0 stored as bytes in memory (estimated size 1887.0 B, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Added broadcast_1_piece0 in memory on cluster01:44766 (size: 1887.0 B, free: 3.6 GB)
[actor] handled message (0.402563 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Put block broadcast_1_piece0 locally took  2 ms
Putting block broadcast_1_piece0 without replication took  2 ms
Submitting 1 missing tasks from Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68)
New pending tasks: Set(ResultTask(0, 0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (2.017194 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150123125146-0005/0 is now RUNNING
[actor] handled message (0.23522 ms) ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150123125146-0005/2 is now RUNNING
[actor] handled message (0.192672 ms) ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150123125146-0005/1 is now RUNNING
[actor] handled message (0.17559 ms) ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.436586 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.486405 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:48948/temp/$a]
[actor] handled message (0.053757 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:48948/temp/$a]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:38435/temp/$a]
[actor] handled message (0.024217 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:38435/temp/$a]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:34388] <- [akka.tcp://driverPropsFetcher@cluster02:48948] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.437971 ms) Disassociated [akka.tcp://sparkDriver@cluster01:34388] <- [akka.tcp://driverPropsFetcher@cluster02:48948] from Actor[akka://sparkDriver/deadLetters]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:34388] <- [akka.tcp://driverPropsFetcher@cluster03:38435] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.019753 ms) Disassociated [akka.tcp://sparkDriver@cluster01:34388] <- [akka.tcp://driverPropsFetcher@cluster03:38435] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(0,cluster02:44086,2) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822] with ID 0
parentName: , name: TaskSet_0, runningTasks: 0
Valid locality levels for TaskSet 0.0: ANY
Starting task 0.0 in stage 0.0 (TID 0, cluster02, ANY, 1903 bytes)
[actor] handled message (16.003856 ms) RegisterExecutor(0,cluster02:44086,2) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:40005/temp/$a]
[actor] handled message (0.021376 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:40005/temp/$a]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:34388] <- [akka.tcp://driverPropsFetcher@cluster01:40005] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.016388 ms) Disassociated [akka.tcp://sparkDriver@cluster01:34388] <- [akka.tcp://driverPropsFetcher@cluster01:40005] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(2,cluster03:33413,2) from Actor[akka.tcp://sparkExecutor@cluster03:33413/user/Executor#-1722066066]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster03:33413/user/Executor#-1722066066] with ID 2
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (1.590057 ms) RegisterExecutor(2,cluster03:33413,2) from Actor[akka.tcp://sparkExecutor@cluster03:33413/user/Executor#-1722066066]
[actor] received message RegisterBlockManager(BlockManagerId(0, cluster02, 45239, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:33470/user/BlockManagerActor1#-1552833137]) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$c]
Registering block manager cluster02:45239 with 3.1 GB RAM, BlockManagerId(0, cluster02, 45239, 0)
[actor] received message RegisterExecutor(1,cluster01:39887,2) from Actor[akka.tcp://sparkExecutor@cluster01:39887/user/Executor#748518448]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster01:39887/user/Executor#748518448] with ID 1
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (1.175806 ms) RegisterExecutor(1,cluster01:39887,2) from Actor[akka.tcp://sparkExecutor@cluster01:39887/user/Executor#748518448]
[actor] handled message (2.589869 ms) RegisterBlockManager(BlockManagerId(0, cluster02, 45239, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:33470/user/BlockManagerActor1#-1552833137]) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$c]
[actor] received message RegisterBlockManager(BlockManagerId(2, cluster03, 33147, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:52358/user/BlockManagerActor1#-177854557]) from Actor[akka.tcp://sparkExecutor@cluster03:52358/temp/$c]
Registering block manager cluster03:33147 with 3.1 GB RAM, BlockManagerId(2, cluster03, 33147, 0)
[actor] handled message (1.447772 ms) RegisterBlockManager(BlockManagerId(2, cluster03, 33147, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:52358/user/BlockManagerActor1#-177854557]) from Actor[akka.tcp://sparkExecutor@cluster03:52358/temp/$c]
[actor] received message StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@3974a83a) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] handled message (0.552171 ms) StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@3974a83a) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] received message RegisterBlockManager(BlockManagerId(1, cluster01, 37403, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:45759/user/BlockManagerActor1#-1749333963]) from Actor[akka.tcp://sparkExecutor@cluster01:45759/temp/$c]
Registering block manager cluster01:37403 with 3.1 GB RAM, BlockManagerId(1, cluster01, 37403, 0)
[actor] handled message (0.474165 ms) RegisterBlockManager(BlockManagerId(1, cluster01, 37403, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:45759/user/BlockManagerActor1#-1749333963]) from Actor[akka.tcp://sparkExecutor@cluster01:45759/temp/$c]
[actor] received message GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$e]
[actor] handled message (0.104941 ms) GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$e]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.614842 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
Accepted connection from [cluster02/192.168.2.2:33292]
Selector selected 0 of 2 keys
Starting to receive [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Finished receiving [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,45239)] in 2 ms
Received [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 2 keys
Handler thread delay is 11 ms
Handling [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Calling back
Handling message BufferMessage(id = 3, size = 48)
Handling as a buffer message BufferMessage(id = 3, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_1_piece0, level = null, data = null]
Converted block message array from buffer message in 0.009 s
Parsed as a block message array
Received [GetBlock(broadcast_1_piece0)]
GetBlock broadcast_1_piece0 started from 1421988709293
Getting local block broadcast_1_piece0 as bytes
Level for block broadcast_1_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_1_piece0 from memory
GetBlock broadcast_1_piece0 used  2 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Adding BlockMessage [type = 2, id = broadcast_1_piece0, level = null, data = 1887]
Added BufferMessage(id = 2, size = 1935)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Response to BufferMessage(id = 3, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,45239)] connectionid: cluster01_44766_2
Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,45239)]
Added [BufferAckMessage(aid = 3, id = 3, size = 1939)] to outbox for sending to [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 2 keys
Handling delay is 56 ms
Initiating connection to [cluster02/192.168.2.2:45239]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Connected to [cluster02/192.168.2.2:45239], 1 messages pending
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,45239)]
Finished sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,45239)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$f]
Added broadcast_1_piece0 in memory on cluster02:45239 (size: 1887.0 B, free: 3.1 GB)
[actor] handled message (0.426456 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$f]
[actor] received message GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$g]
[actor] handled message (0.093124 ms) GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$g]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Finished receiving [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,45239)] in 1 ms
Received [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Handler thread delay is 0 ms
Handling [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Calling back
Handling message BufferMessage(id = 5, size = 48)
Handling as a buffer message BufferMessage(id = 5, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_0_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_0_piece0)]
GetBlock broadcast_0_piece0 started from 1421988709412
Getting local block broadcast_0_piece0 as bytes
Level for block broadcast_0_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_0_piece0 from memory
GetBlock broadcast_0_piece0 used  0 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Adding BlockMessage [type = 2, id = broadcast_0_piece0, level = null, data = 12633]
Added BufferMessage(id = 4, size = 12681)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Response to BufferMessage(id = 5, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,45239)] connectionid: cluster01_44766_2
Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,45239)]
Added [BufferAckMessage(aid = 5, id = 5, size = 12685)] to outbox for sending to [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Handling delay is 2 ms
Starting to send [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,45239)]
Finished sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,45239)] in 0 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$h]
Added broadcast_0_piece0 in memory on cluster02:45239 (size: 12.3 KB, free: 3.1 GB)
[actor] handled message (0.471028 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$h]
[actor] received message GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$i]
[actor] handled message (0.038214 ms) GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$i]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.642417 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.805515 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.599731 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.616781 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.575142 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.606219 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.604815 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),rdd_3_0,StorageLevel(false, true, false, true, 1),212376952,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$j]
Added rdd_3_0 in memory on cluster02:45239 (size: 202.5 MB, free: 2.9 GB)
[actor] handled message (0.763903 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),rdd_3_0,StorageLevel(false, true, false, true, 1),212376952,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$j]
[actor] received message StatusUpdate(0,0,FINISHED,org.apache.spark.util.SerializableBuffer@4cf3a603) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.962513 ms) StatusUpdate(0,0,FINISHED,org.apache.spark.util.SerializableBuffer@4cf3a603) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
Stage 0 (count at GraphLoader.scala:87) finished in 9.444 s
After removal of stage 0, remaining stages = 0
Job finished: count at GraphLoader.scala:87, took 9.519106668 s
Finished task 0.0 in stage 0.0 (TID 0) in 7688 ms on cluster02 (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
It took 10068 ms to load the edges
Starting job: reduce at VertexRDD.scala:111
Registering RDD 6 (mapPartitions at VertexRDD.scala:452)
Got job 1 (reduce at VertexRDD.scala:111) with 1 output partitions (allowLocal=false)
Final stage: Stage 1(reduce at VertexRDD.scala:111)
Parents of final stage: List(Stage 2)
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2a23741b) from Actor[akka://sparkDriver/temp/$j]
[actor] handled message (0.086818 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2a23741b) from Actor[akka://sparkDriver/temp/$j]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7d9bae39) from Actor[akka://sparkDriver/temp/$k]
[actor] handled message (0.075024 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@7d9bae39) from Actor[akka://sparkDriver/temp/$k]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@77cb609b) from Actor[akka://sparkDriver/temp/$l]
[actor] handled message (0.07089 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@77cb609b) from Actor[akka://sparkDriver/temp/$l]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@49339d8e) from Actor[akka://sparkDriver/temp/$m]
[actor] handled message (0.066899 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@49339d8e) from Actor[akka://sparkDriver/temp/$m]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5bacfb2d) from Actor[akka://sparkDriver/temp/$n]
[actor] handled message (0.06566 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5bacfb2d) from Actor[akka://sparkDriver/temp/$n]
Missing parents: List(Stage 2)
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6dd938f0) from Actor[akka://sparkDriver/temp/$o]
[actor] handled message (0.06682 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6dd938f0) from Actor[akka://sparkDriver/temp/$o]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50294ce7) from Actor[akka://sparkDriver/temp/$p]
[actor] handled message (0.124582 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50294ce7) from Actor[akka://sparkDriver/temp/$p]
missing: List()
Submitting Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452), which has no missing parents
submitMissingTasks(Stage 2)
ensureFreeSpace(3816) called with curMem=181345, maxMem=3890007244
Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 3.6 GB)
Put block broadcast_2 locally took  1 ms
Putting block broadcast_2 without replication took  1 ms
ensureFreeSpace(2263) called with curMem=185161, maxMem=3890007244
Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka://sparkDriver/temp/$q]
Added broadcast_2_piece0 in memory on cluster01:44766 (size: 2.2 KB, free: 3.6 GB)
[actor] handled message (0.347629 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka://sparkDriver/temp/$q]
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Put block broadcast_2_piece0 locally took  1 ms
Putting block broadcast_2_piece0 without replication took  1 ms
Submitting 1 missing tasks from Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452)
New pending tasks: Set(ShuffleMapTask(2, 0))
Adding task set 2.0 with 1 tasks
Epoch for TaskSet 2.0: 0
Valid locality levels for TaskSet 2.0: PROCESS_LOCAL, NODE_LOCAL, ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
parentName: , name: TaskSet_2, runningTasks: 0
Starting task 0.0 in stage 2.0 (TID 1, cluster02, PROCESS_LOCAL, 1892 bytes)
submitStage(Stage 1)
[actor] handled message (2.706715 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
missing: List(Stage 2)
submitStage(Stage 2)
[actor] received message StatusUpdate(0,1,RUNNING,org.apache.spark.util.SerializableBuffer@2f62013e) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] handled message (0.042329 ms) StatusUpdate(0,1,RUNNING,org.apache.spark.util.SerializableBuffer@2f62013e) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] received message GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$k]
[actor] handled message (0.108155 ms) GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$k]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Finished receiving [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,45239)] in 1 ms
Received [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Handler thread delay is 0 ms
Handling [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Calling back
Handling message BufferMessage(id = 7, size = 48)
Handling as a buffer message BufferMessage(id = 7, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_2_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_2_piece0)]
GetBlock broadcast_2_piece0 started from 1421988716495
Getting local block broadcast_2_piece0 as bytes
Level for block broadcast_2_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_2_piece0 from memory
GetBlock broadcast_2_piece0 used  0 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=2263 cap=2263]
Adding BlockMessage [type = 2, id = broadcast_2_piece0, level = null, data = 2263]
Added BufferMessage(id = 6, size = 2311)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=2263 cap=2263]
Response to BufferMessage(id = 7, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,45239)] connectionid: cluster01_44766_2
Sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,45239)]
Added [BufferAckMessage(aid = 7, id = 7, size = 2315)] to outbox for sending to [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Handling delay is 3 ms
Finished sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,45239)] in 0 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$l]
Added broadcast_2_piece0 in memory on cluster02:45239 (size: 2.2 KB, free: 2.9 GB)
[actor] handled message (0.605803 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$l]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_2, runningTasks: 1
[actor] handled message (0.693228 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message StatusUpdate(0,1,FINISHED,org.apache.spark.util.SerializableBuffer@5373be4a) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
parentName: , name: TaskSet_2, runningTasks: 0
[actor] handled message (0.609267 ms) StatusUpdate(0,1,FINISHED,org.apache.spark.util.SerializableBuffer@5373be4a) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
ShuffleMapTask finished on 0
Stage 2 (mapPartitions at VertexRDD.scala:452) finished in 1.690 s
looking for newly runnable stages
Finished task 0.0 in stage 2.0 (TID 1) in 1689 ms on cluster02 (1/1)
running: Set()
Removed TaskSet 2.0, whose tasks have all completed, from pool 
waiting: Set(Stage 1)
failed: Set()
Increasing epoch to 1
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6468836) from Actor[akka://sparkDriver/temp/$r]
[actor] handled message (0.081719 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6468836) from Actor[akka://sparkDriver/temp/$r]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@989472) from Actor[akka://sparkDriver/temp/$s]
[actor] handled message (0.059575 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@989472) from Actor[akka://sparkDriver/temp/$s]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2139c8ac) from Actor[akka://sparkDriver/temp/$t]
[actor] handled message (0.058851 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2139c8ac) from Actor[akka://sparkDriver/temp/$t]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@58a5a53e) from Actor[akka://sparkDriver/temp/$u]
[actor] handled message (0.060574 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@58a5a53e) from Actor[akka://sparkDriver/temp/$u]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6303b6e9) from Actor[akka://sparkDriver/temp/$v]
[actor] handled message (0.057353 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6303b6e9) from Actor[akka://sparkDriver/temp/$v]
Missing parents for Stage 1: List()
Submitting Stage 1 (MappedRDD[27] at map at VertexRDD.scala:111), which is now runnable
submitMissingTasks(Stage 1)
ensureFreeSpace(4168) called with curMem=187424, maxMem=3890007244
Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 3.6 GB)
Put block broadcast_3 locally took  1 ms
Putting block broadcast_3 without replication took  1 ms
ensureFreeSpace(2251) called with curMem=191592, maxMem=3890007244
Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka://sparkDriver/temp/$w]
Added broadcast_3_piece0 in memory on cluster01:44766 (size: 2.2 KB, free: 3.6 GB)
Updated info of block broadcast_3_piece0
[actor] handled message (0.336892 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 44766, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka://sparkDriver/temp/$w]
Told master about block broadcast_3_piece0
Put block broadcast_3_piece0 locally took  1 ms
Putting block broadcast_3_piece0 without replication took  1 ms
Submitting 1 missing tasks from Stage 1 (MappedRDD[27] at map at VertexRDD.scala:111)
New pending tasks: Set(ResultTask(1, 0))
Adding task set 1.0 with 1 tasks
Epoch for TaskSet 1.0: 1
Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_1, runningTasks: 0
Starting task 0.0 in stage 1.0 (TID 2, cluster02, PROCESS_LOCAL, 1055 bytes)
[actor] handled message (1.260866 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message StatusUpdate(0,2,RUNNING,org.apache.spark.util.SerializableBuffer@7ae4e605) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] handled message (0.043019 ms) StatusUpdate(0,2,RUNNING,org.apache.spark.util.SerializableBuffer@7ae4e605) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
[actor] received message GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$m]
[actor] handled message (0.080668 ms) GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$m]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 9, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Finished receiving [BufferMessage(id = 9, size = 48)] from [ConnectionManagerId(cluster02,45239)] in 0 ms
Received [BufferMessage(id = 9, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Handler thread delay is 0 ms
Handling [BufferMessage(id = 9, size = 48)] from [ConnectionManagerId(cluster02,45239)]
Calling back
Handling message BufferMessage(id = 9, size = 48)
Handling as a buffer message BufferMessage(id = 9, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_3_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_3_piece0)]
GetBlock broadcast_3_piece0 started from 1421988718195
Getting local block broadcast_3_piece0 as bytes
Level for block broadcast_3_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_3_piece0 from memory
GetBlock broadcast_3_piece0 used  1 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=2251 cap=2251]
Adding BlockMessage [type = 2, id = broadcast_3_piece0, level = null, data = 2251]
Added BufferMessage(id = 8, size = 2299)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=2251 cap=2251]
Response to BufferMessage(id = 9, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 9, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,45239)] connectionid: cluster01_44766_2
Sending [BufferAckMessage(aid = 9, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,45239)]
Added [BufferAckMessage(aid = 9, id = 9, size = 2303)] to outbox for sending to [ConnectionManagerId(cluster02,45239)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 9, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,45239)]
Handling delay is 1 ms
Finished sending [BufferAckMessage(aid = 9, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,45239)] in 1 ms
Selector selected 0 of 3 keys
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$n]
Added broadcast_3_piece0 in memory on cluster02:45239 (size: 2.2 KB, free: 2.9 GB)
[actor] handled message (0.36549 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$n]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
parentName: , name: TaskSet_1, runningTasks: 1
[actor] handled message (0.728485 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1252859668]
[actor] received message GetLocations(rdd_9_0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$o]
[actor] handled message (0.062815 ms) GetLocations(rdd_9_0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$o]
[actor] received message GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$p]
Asked to send map output locations for shuffle 0 to sparkExecutor@cluster02:33470
Size of output statuses for shuffle 0 is 127 bytes
[actor] handled message (2.76059 ms) GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$p]
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),rdd_9_0,StorageLevel(false, true, false, true, 1),67069416,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$q]
Added rdd_9_0 in memory on cluster02:45239 (size: 64.0 MB, free: 2.8 GB)
[actor] handled message (0.745815 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 45239, 0),rdd_9_0,StorageLevel(false, true, false, true, 1),67069416,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:33470/temp/$q]
[actor] received message StatusUpdate(0,2,FINISHED,org.apache.spark.util.SerializableBuffer@6255e7ef) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
parentName: , name: TaskSet_1, runningTasks: 0
[actor] handled message (1.166529 ms) StatusUpdate(0,2,FINISHED,org.apache.spark.util.SerializableBuffer@6255e7ef) from Actor[akka.tcp://sparkExecutor@cluster02:44086/user/Executor#-556292822]
Finished task 0.0 in stage 1.0 (TID 2) in 835 ms on cluster02 (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
Stage 1 (reduce at VertexRDD.scala:111) finished in 0.838 s
After removal of stage 2, remaining stages = 1
After removal of stage 1, remaining stages = 0
Job finished: reduce at VertexRDD.scala:111, took 2.560646998 s
Shutdown hook called
Changing view acls to: renq
Changing modify acls to: renq
SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(renq); users with modify permissions: Set(renq)
In createActorSystem, requireCookie is: off
Slf4jLogger started
Starting remoting
Remoting started; listening on addresses :[akka.tcp://sparkDriver@cluster01:56056]
Remoting now listens on addresses: [akka.tcp://sparkDriver@cluster01:56056]
Successfully started service 'sparkDriver' on port 56056.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
Registering BlockManagerMaster
[actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#-506872868]
[actor] handled message (1.393313 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#-506872868]
Getting/creating local root dirs at '/tmp'
Created local directory at /tmp/spark-local-20150124153945-b27f
Using SLF4J as the default logging framework
-Dio.netty.leakDetectionLevel: simple
java.nio.Buffer.address: available
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Bits.unaligned: true
UID: 1002
Java version: 7
-Dio.netty.noUnsafe: false
sun.misc.Unsafe: available
-Dio.netty.noJavassist: false
Javassist: unavailable
You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
Successfully started service 'Connection manager for block manager' on port 51472.
Bound socket to port 51472 with id = ConnectionManagerId(cluster01,51472)
MemoryStore started with capacity 3.6 GB
Trying to register BlockManager
[actor] received message RegisterBlockManager(BlockManagerId(<driver>, cluster01, 51472, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-1513491747]) from Actor[akka://sparkDriver/temp/$a]
Registering block manager cluster01:51472 with 3.6 GB RAM, BlockManagerId(<driver>, cluster01, 51472, 0)
Registered BlockManager
[actor] handled message (2.01143 ms) RegisterBlockManager(BlockManagerId(<driver>, cluster01, 51472, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-1513491747]) from Actor[akka://sparkDriver/temp/$a]
HTTP File server directory is /tmp/spark-dcd8d936-398c-443f-ae13-befd062f4c12
Starting HTTP Server
HttpServer is not using security
Successfully started service 'HTTP file server' on port 37758.
HTTP file server started at: http://192.168.2.1:37758
Successfully started service 'SparkUI' on port 4040.
Started SparkUI at http://cluster01:4040
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:265)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:290)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
	at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:283)
	at org.apache.spark.deploy.SparkHadoopUtil.<init>(SparkHadoopUtil.scala:36)
	at org.apache.spark.deploy.SparkHadoopUtil$.<init>(SparkHadoopUtil.scala:109)
	at org.apache.spark.deploy.SparkHadoopUtil$.<clinit>(SparkHadoopUtil.scala)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:238)
	at Toughness$.main(toughness.scala:12)
	at Toughness.main(toughness.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:329)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
setsid exited with exit code 0
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
Added JAR file:/home/renq/k-tough/target/scala-2.10/toughness_2.10-1.0.jar at http://192.168.2.1:37758/jars/toughness_2.10-1.0.jar with timestamp 1422085185909
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
Connecting to master spark://cluster01:7077...
[actor] handled message (15.052529 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[actor] received message RegisteredApplication(app-20150124153946-0009,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Connected to Spark cluster with app ID app-20150124153946-0009
[actor] handled message (0.97749 ms) RegisteredApplication(app-20150124153946-0009,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124153946-0009/0 on worker-20150121184032-cluster02-48233 (cluster02:48233) with 2 cores
Granted executor ID app-20150124153946-0009/0 on hostPort cluster02:48233 with 2 cores, 6.0 GB RAM
[actor] handled message (1.311608 ms) ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124153946-0009/1 on worker-20150121184029-cluster01-58596 (cluster01:58596) with 2 cores
Granted executor ID app-20150124153946-0009/1 on hostPort cluster01:58596 with 2 cores, 6.0 GB RAM
[actor] handled message (0.346524 ms) ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124153946-0009/2 on worker-20150121184032-cluster03-48380 (cluster03:48380) with 2 cores
Granted executor ID app-20150124153946-0009/2 on hostPort cluster03:48380 with 2 cores, 6.0 GB RAM
[actor] handled message (0.398649 ms) ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124153946-0009/2 is now LOADING
[actor] handled message (1.039826 ms) ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124153946-0009/0 is now LOADING
[actor] handled message (0.184311 ms) ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
ensureFreeSpace(163705) called with curMem=0, maxMem=3890007244
[actor] received message ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124153946-0009/1 is now LOADING
[actor] handled message (0.178062 ms) ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Block broadcast_0 stored as values in memory (estimated size 159.9 KB, free 3.6 GB)
Put block broadcast_0 locally took  197 ms
Putting block broadcast_0 without replication took  201 ms
ensureFreeSpace(12633) called with curMem=163705, maxMem=3890007244
Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.3 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51472, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Added broadcast_0_piece0 in memory on cluster01:51472 (size: 12.3 KB, free: 3.6 GB)
[actor] handled message (0.923894 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51472, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  3 ms
Putting block broadcast_0_piece0 without replication took  5 ms
Creating new JobConf and caching it for later re-use
hadoop login
hadoop login commit
using local user:UnixPrincipal: renq
UGI loginUser:renq (auth:SIMPLE)
Time taken to get FileStatuses: 4
Total input paths to process : 1
Total # of splits generated by getSplits: 3, TimeTaken: 8
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50d20677) from Actor[akka://sparkDriver/temp/$c]
[actor] handled message (0.372985 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@50d20677) from Actor[akka://sparkDriver/temp/$c]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3d474f20) from Actor[akka://sparkDriver/temp/$d]
[actor] handled message (0.138501 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3d474f20) from Actor[akka://sparkDriver/temp/$d]
Starting job: count at GraphLoader.scala:87
Got job 0 (count at GraphLoader.scala:87) with 1 output partitions (allowLocal=false)
Final stage: Stage 0(count at GraphLoader.scala:87)
Parents of final stage: List()
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1e25a060) from Actor[akka://sparkDriver/temp/$e]
[actor] handled message (0.098318 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1e25a060) from Actor[akka://sparkDriver/temp/$e]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@21805932) from Actor[akka://sparkDriver/temp/$f]
[actor] handled message (0.079085 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@21805932) from Actor[akka://sparkDriver/temp/$f]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@715ff2cc) from Actor[akka://sparkDriver/temp/$g]
[actor] handled message (0.088941 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@715ff2cc) from Actor[akka://sparkDriver/temp/$g]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@523d693a) from Actor[akka://sparkDriver/temp/$h]
[actor] handled message (0.104972 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@523d693a) from Actor[akka://sparkDriver/temp/$h]
Missing parents: List()
submitStage(Stage 0)
missing: List()
Submitting Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68), which has no missing parents
submitMissingTasks(Stage 0)
ensureFreeSpace(3120) called with curMem=176338, maxMem=3890007244
Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 3.6 GB)
Put block broadcast_1 locally took  1 ms
Putting block broadcast_1 without replication took  1 ms
ensureFreeSpace(1887) called with curMem=179458, maxMem=3890007244
Block broadcast_1_piece0 stored as bytes in memory (estimated size 1887.0 B, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51472, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Added broadcast_1_piece0 in memory on cluster01:51472 (size: 1887.0 B, free: 3.6 GB)
[actor] handled message (0.610417 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51472, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Put block broadcast_1_piece0 locally took  2 ms
Putting block broadcast_1_piece0 without replication took  2 ms
Submitting 1 missing tasks from Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68)
New pending tasks: Set(ResultTask(0, 0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (1.986724 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124153946-0009/0 is now RUNNING
[actor] handled message (0.174225 ms) ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124153946-0009/2 is now RUNNING
[actor] handled message (0.195258 ms) ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124153946-0009/1 is now RUNNING
[actor] handled message (0.255331 ms) ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.550877 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.390066 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:41960/temp/$a]
[actor] handled message (0.034076 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:41960/temp/$a]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:58285/temp/$a]
[actor] handled message (0.019635 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:58285/temp/$a]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:40427/temp/$a]
[actor] handled message (0.019271 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:40427/temp/$a]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:56056] <- [akka.tcp://driverPropsFetcher@cluster02:41960] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.297841 ms) Disassociated [akka.tcp://sparkDriver@cluster01:56056] <- [akka.tcp://driverPropsFetcher@cluster02:41960] from Actor[akka://sparkDriver/deadLetters]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:56056] <- [akka.tcp://driverPropsFetcher@cluster03:58285] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.015462 ms) Disassociated [akka.tcp://sparkDriver@cluster01:56056] <- [akka.tcp://driverPropsFetcher@cluster03:58285] from Actor[akka://sparkDriver/deadLetters]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:56056] <- [akka.tcp://driverPropsFetcher@cluster01:40427] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.012014 ms) Disassociated [akka.tcp://sparkDriver@cluster01:56056] <- [akka.tcp://driverPropsFetcher@cluster01:40427] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(0,cluster02:58861,2) from Actor[akka.tcp://sparkExecutor@cluster02:58861/user/Executor#829443389]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster02:58861/user/Executor#829443389] with ID 0
parentName: , name: TaskSet_0, runningTasks: 0
Valid locality levels for TaskSet 0.0: ANY
Starting task 0.0 in stage 0.0 (TID 0, cluster02, ANY, 1903 bytes)
[actor] handled message (36.771302 ms) RegisterExecutor(0,cluster02:58861,2) from Actor[akka.tcp://sparkExecutor@cluster02:58861/user/Executor#829443389]
[actor] received message RegisterExecutor(2,cluster03:47341,2) from Actor[akka.tcp://sparkExecutor@cluster03:47341/user/Executor#-1902615378]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster03:47341/user/Executor#-1902615378] with ID 2
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (2.141125 ms) RegisterExecutor(2,cluster03:47341,2) from Actor[akka.tcp://sparkExecutor@cluster03:47341/user/Executor#-1902615378]
[actor] received message RegisterExecutor(1,cluster01:57472,2) from Actor[akka.tcp://sparkExecutor@cluster01:57472/user/Executor#119554535]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster01:57472/user/Executor#119554535] with ID 1
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (1.421824 ms) RegisterExecutor(1,cluster01:57472,2) from Actor[akka.tcp://sparkExecutor@cluster01:57472/user/Executor#119554535]
[actor] received message RegisterBlockManager(BlockManagerId(0, cluster02, 44970, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:59272/user/BlockManagerActor1#-926058673]) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$c]
Registering block manager cluster02:44970 with 3.1 GB RAM, BlockManagerId(0, cluster02, 44970, 0)
[actor] handled message (0.333897 ms) RegisterBlockManager(BlockManagerId(0, cluster02, 44970, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:59272/user/BlockManagerActor1#-926058673]) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$c]
[actor] received message RegisterBlockManager(BlockManagerId(2, cluster03, 56277, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:38291/user/BlockManagerActor1#164776325]) from Actor[akka.tcp://sparkExecutor@cluster03:38291/temp/$c]
Registering block manager cluster03:56277 with 3.1 GB RAM, BlockManagerId(2, cluster03, 56277, 0)
[actor] handled message (0.417122 ms) RegisterBlockManager(BlockManagerId(2, cluster03, 56277, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:38291/user/BlockManagerActor1#164776325]) from Actor[akka.tcp://sparkExecutor@cluster03:38291/temp/$c]
[actor] received message RegisterBlockManager(BlockManagerId(1, cluster01, 54330, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:46057/user/BlockManagerActor1#1045167375]) from Actor[akka.tcp://sparkExecutor@cluster01:46057/temp/$c]
Registering block manager cluster01:54330 with 3.1 GB RAM, BlockManagerId(1, cluster01, 54330, 0)
[actor] handled message (1.128308 ms) RegisterBlockManager(BlockManagerId(1, cluster01, 54330, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:46057/user/BlockManagerActor1#1045167375]) from Actor[akka.tcp://sparkExecutor@cluster01:46057/temp/$c]
[actor] received message StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@280f943a) from Actor[akka.tcp://sparkExecutor@cluster02:58861/user/Executor#829443389]
[actor] handled message (0.432188 ms) StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@280f943a) from Actor[akka.tcp://sparkExecutor@cluster02:58861/user/Executor#829443389]
[actor] received message GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$e]
[actor] handled message (0.108962 ms) GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$e]
Accepted connection from [cluster02/192.168.2.2:55273]
Selector selected 0 of 2 keys
Starting to receive [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,44970)]
Finished receiving [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,44970)] in 2 ms
Received [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,44970)]
Selector selected 0 of 2 keys
Handler thread delay is 2 ms
Handling [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,44970)]
Calling back
Handling message BufferMessage(id = 3, size = 48)
Handling as a buffer message BufferMessage(id = 3, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_1_piece0, level = null, data = null]
Converted block message array from buffer message in 0.004 s
Parsed as a block message array
Received [GetBlock(broadcast_1_piece0)]
GetBlock broadcast_1_piece0 started from 1422085188848
Getting local block broadcast_1_piece0 as bytes
Level for block broadcast_1_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_1_piece0 from memory
GetBlock broadcast_1_piece0 used  2 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Adding BlockMessage [type = 2, id = broadcast_1_piece0, level = null, data = 1887]
Added BufferMessage(id = 2, size = 1935)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Response to BufferMessage(id = 3, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,44970)] connectionid: cluster01_51472_2
Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,44970)]
Added [BufferAckMessage(aid = 3, id = 3, size = 1939)] to outbox for sending to [ConnectionManagerId(cluster02,44970)]
Selector selected 0 of 2 keys
Handling delay is 18 ms
Initiating connection to [cluster02/192.168.2.2:44970]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Connected to [cluster02/192.168.2.2:44970], 1 messages pending
Starting to send [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,44970)]
Finished sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,44970)] in 2 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 44970, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$f]
Added broadcast_1_piece0 in memory on cluster02:44970 (size: 1887.0 B, free: 3.1 GB)
[actor] handled message (0.919166 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 44970, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$f]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.552789 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
[actor] received message GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$g]
[actor] handled message (0.238418 ms) GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$g]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,44970)]
Finished receiving [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,44970)] in 0 ms
Received [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,44970)]
Selector selected 0 of 3 keys
Handler thread delay is 0 ms
Handling [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,44970)]
Calling back
Handling message BufferMessage(id = 5, size = 48)
Handling as a buffer message BufferMessage(id = 5, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_0_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_0_piece0)]
GetBlock broadcast_0_piece0 started from 1422085188988
Getting local block broadcast_0_piece0 as bytes
Level for block broadcast_0_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_0_piece0 from memory
GetBlock broadcast_0_piece0 used  0 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Adding BlockMessage [type = 2, id = broadcast_0_piece0, level = null, data = 12633]
Added BufferMessage(id = 4, size = 12681)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Response to BufferMessage(id = 5, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,44970)] connectionid: cluster01_51472_2
Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,44970)]
Added [BufferAckMessage(aid = 5, id = 5, size = 12685)] to outbox for sending to [ConnectionManagerId(cluster02,44970)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Handling delay is 2 ms
Starting to send [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,44970)]
Finished sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,44970)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 44970, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$h]
Added broadcast_0_piece0 in memory on cluster02:44970 (size: 12.3 KB, free: 3.1 GB)
[actor] handled message (0.91754 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 44970, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$h]
[actor] received message GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$i]
[actor] handled message (0.04841 ms) GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster02:59272/temp/$i]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.968796 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.589202 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#11198931]
Shutdown hook called
Changing view acls to: renq
Changing modify acls to: renq
SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(renq); users with modify permissions: Set(renq)
In createActorSystem, requireCookie is: off
Slf4jLogger started
Starting remoting
Remoting started; listening on addresses :[akka.tcp://sparkDriver@cluster01:37888]
Remoting now listens on addresses: [akka.tcp://sparkDriver@cluster01:37888]
Successfully started service 'sparkDriver' on port 37888.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
Registering BlockManagerMaster
[actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#-1569842403]
[actor] handled message (1.402117 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#-1569842403]
Getting/creating local root dirs at '/tmp'
Created local directory at /tmp/spark-local-20150124154015-4664
Using SLF4J as the default logging framework
-Dio.netty.leakDetectionLevel: simple
java.nio.Buffer.address: available
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Bits.unaligned: true
UID: 1002
Java version: 7
-Dio.netty.noUnsafe: false
sun.misc.Unsafe: available
-Dio.netty.noJavassist: false
Javassist: unavailable
You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
Successfully started service 'Connection manager for block manager' on port 38584.
Bound socket to port 38584 with id = ConnectionManagerId(cluster01,38584)
MemoryStore started with capacity 3.6 GB
Trying to register BlockManager
[actor] received message RegisterBlockManager(BlockManagerId(<driver>, cluster01, 38584, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-1877606792]) from Actor[akka://sparkDriver/temp/$a]
Registering block manager cluster01:38584 with 3.6 GB RAM, BlockManagerId(<driver>, cluster01, 38584, 0)
[actor] handled message (1.900459 ms) RegisterBlockManager(BlockManagerId(<driver>, cluster01, 38584, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-1877606792]) from Actor[akka://sparkDriver/temp/$a]
Registered BlockManager
HTTP File server directory is /tmp/spark-e47e3e44-e487-43aa-9448-b619d3c078b5
Starting HTTP Server
HttpServer is not using security
Successfully started service 'HTTP file server' on port 39464.
HTTP file server started at: http://192.168.2.1:39464
Successfully started service 'SparkUI' on port 4040.
Started SparkUI at http://cluster01:4040
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:265)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:290)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
	at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:283)
	at org.apache.spark.deploy.SparkHadoopUtil.<init>(SparkHadoopUtil.scala:36)
	at org.apache.spark.deploy.SparkHadoopUtil$.<init>(SparkHadoopUtil.scala:109)
	at org.apache.spark.deploy.SparkHadoopUtil$.<clinit>(SparkHadoopUtil.scala)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:238)
	at Toughness$.main(toughness.scala:12)
	at Toughness.main(toughness.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:329)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
setsid exited with exit code 0
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
Added JAR file:/home/renq/k-tough/target/scala-2.10/toughness_2.10-1.0.jar at http://192.168.2.1:39464/jars/toughness_2.10-1.0.jar with timestamp 1422085216108
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-1651752141]
Connecting to master spark://cluster01:7077...
[actor] handled message (16.150626 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-1651752141]
SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[actor] received message RegisteredApplication(app-20150124154016-0010,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Connected to Spark cluster with app ID app-20150124154016-0010
[actor] handled message (0.816775 ms) RegisteredApplication(app-20150124154016-0010,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124154016-0010/0 on worker-20150121184032-cluster02-48233 (cluster02:48233) with 2 cores
Granted executor ID app-20150124154016-0010/0 on hostPort cluster02:48233 with 2 cores, 6.0 GB RAM
[actor] handled message (2.694375 ms) ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124154016-0010/1 on worker-20150121184029-cluster01-58596 (cluster01:58596) with 2 cores
Granted executor ID app-20150124154016-0010/1 on hostPort cluster01:58596 with 2 cores, 6.0 GB RAM
[actor] handled message (0.446959 ms) ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124154016-0010/2 on worker-20150121184032-cluster03-48380 (cluster03:48380) with 2 cores
Granted executor ID app-20150124154016-0010/2 on hostPort cluster03:48380 with 2 cores, 6.0 GB RAM
[actor] handled message (0.353975 ms) ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154016-0010/0 is now LOADING
[actor] handled message (0.913906 ms) ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154016-0010/1 is now LOADING
[actor] handled message (0.180536 ms) ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154016-0010/2 is now LOADING
[actor] handled message (0.178774 ms) ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
ensureFreeSpace(163705) called with curMem=0, maxMem=3890007244
Block broadcast_0 stored as values in memory (estimated size 159.9 KB, free 3.6 GB)
Put block broadcast_0 locally took  225 ms
Putting block broadcast_0 without replication took  225 ms
ensureFreeSpace(12633) called with curMem=163705, maxMem=3890007244
Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.3 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 38584, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Added broadcast_0_piece0 in memory on cluster01:38584 (size: 12.3 KB, free: 3.6 GB)
[actor] handled message (0.858292 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 38584, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  4 ms
Putting block broadcast_0_piece0 without replication took  4 ms
Creating new JobConf and caching it for later re-use
hadoop login
hadoop login commit
using local user:UnixPrincipal: renq
UGI loginUser:renq (auth:SIMPLE)
Shutdown hook called
Changing view acls to: renq
Changing modify acls to: renq
SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(renq); users with modify permissions: Set(renq)
In createActorSystem, requireCookie is: off
Slf4jLogger started
Starting remoting
Remoting started; listening on addresses :[akka.tcp://sparkDriver@cluster01:37220]
Remoting now listens on addresses: [akka.tcp://sparkDriver@cluster01:37220]
Successfully started service 'sparkDriver' on port 37220.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
Registering BlockManagerMaster
[actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#817401240]
[actor] handled message (1.458527 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#817401240]
Getting/creating local root dirs at '/tmp'
Created local directory at /tmp/spark-local-20150124154143-8e4c
Using SLF4J as the default logging framework
-Dio.netty.leakDetectionLevel: simple
java.nio.Buffer.address: available
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Bits.unaligned: true
UID: 1002
Java version: 7
-Dio.netty.noUnsafe: false
sun.misc.Unsafe: available
-Dio.netty.noJavassist: false
Javassist: unavailable
You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
Successfully started service 'Connection manager for block manager' on port 39937.
Bound socket to port 39937 with id = ConnectionManagerId(cluster01,39937)
MemoryStore started with capacity 3.6 GB
Trying to register BlockManager
[actor] received message RegisterBlockManager(BlockManagerId(<driver>, cluster01, 39937, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-338743854]) from Actor[akka://sparkDriver/temp/$a]
Registering block manager cluster01:39937 with 3.6 GB RAM, BlockManagerId(<driver>, cluster01, 39937, 0)
Registered BlockManager
[actor] handled message (4.226572 ms) RegisterBlockManager(BlockManagerId(<driver>, cluster01, 39937, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-338743854]) from Actor[akka://sparkDriver/temp/$a]
HTTP File server directory is /tmp/spark-b0e95bd4-bf9f-4cae-bc2f-18bcc6a5b113
Starting HTTP Server
HttpServer is not using security
Successfully started service 'HTTP file server' on port 52396.
HTTP file server started at: http://192.168.2.1:52396
Successfully started service 'SparkUI' on port 4040.
Started SparkUI at http://cluster01:4040
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)], about=, always=false, type=DEFAULT, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(valueName=Time, value=[GetGroups], about=, always=false, type=DEFAULT, sampleName=Ops)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:265)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:290)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
	at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:283)
	at org.apache.spark.deploy.SparkHadoopUtil.<init>(SparkHadoopUtil.scala:36)
	at org.apache.spark.deploy.SparkHadoopUtil$.<init>(SparkHadoopUtil.scala:109)
	at org.apache.spark.deploy.SparkHadoopUtil$.<clinit>(SparkHadoopUtil.scala)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:238)
	at Toughness$.main(toughness.scala:12)
	at Toughness.main(toughness.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:329)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
setsid exited with exit code 0
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
Added JAR file:/home/renq/k-tough/target/scala-2.10/toughness_2.10-1.0.jar at http://192.168.2.1:52396/jars/toughness_2.10-1.0.jar with timestamp 1422085304363
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
Connecting to master spark://cluster01:7077...
[actor] handled message (7.59671 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[actor] received message RegisteredApplication(app-20150124154144-0011,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Connected to Spark cluster with app ID app-20150124154144-0011
[actor] handled message (0.93289 ms) RegisteredApplication(app-20150124154144-0011,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124154144-0011/0 on worker-20150121184032-cluster02-48233 (cluster02:48233) with 2 cores
Granted executor ID app-20150124154144-0011/0 on hostPort cluster02:48233 with 2 cores, 6.0 GB RAM
[actor] handled message (1.273774 ms) ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124154144-0011/1 on worker-20150121184029-cluster01-58596 (cluster01:58596) with 2 cores
Granted executor ID app-20150124154144-0011/1 on hostPort cluster01:58596 with 2 cores, 6.0 GB RAM
[actor] handled message (0.403764 ms) ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150124154144-0011/2 on worker-20150121184032-cluster03-48380 (cluster03:48380) with 2 cores
Granted executor ID app-20150124154144-0011/2 on hostPort cluster03:48380 with 2 cores, 6.0 GB RAM
[actor] handled message (0.350512 ms) ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154144-0011/1 is now LOADING
[actor] handled message (1.080111 ms) ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154144-0011/0 is now LOADING
[actor] handled message (0.222436 ms) ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154144-0011/2 is now LOADING
[actor] handled message (0.195262 ms) ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
ensureFreeSpace(163705) called with curMem=0, maxMem=3890007244
Block broadcast_0 stored as values in memory (estimated size 159.9 KB, free 3.6 GB)
Put block broadcast_0 locally took  241 ms
Putting block broadcast_0 without replication took  247 ms
ensureFreeSpace(12633) called with curMem=163705, maxMem=3890007244
Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.3 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Added broadcast_0_piece0 in memory on cluster01:39937 (size: 12.3 KB, free: 3.6 GB)
[actor] handled message (0.912635 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  4 ms
Putting block broadcast_0_piece0 without replication took  12 ms
Creating new JobConf and caching it for later re-use
hadoop login
hadoop login commit
using local user:UnixPrincipal: renq
UGI loginUser:renq (auth:SIMPLE)
Time taken to get FileStatuses: 4
Total input paths to process : 1
Total # of splits generated by getSplits: 3, TimeTaken: 9
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@59b398bd) from Actor[akka://sparkDriver/temp/$c]
[actor] handled message (0.422048 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@59b398bd) from Actor[akka://sparkDriver/temp/$c]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@381b21b7) from Actor[akka://sparkDriver/temp/$d]
[actor] handled message (0.116658 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@381b21b7) from Actor[akka://sparkDriver/temp/$d]
Starting job: count at GraphLoader.scala:87
Got job 0 (count at GraphLoader.scala:87) with 1 output partitions (allowLocal=false)
Final stage: Stage 0(count at GraphLoader.scala:87)
Parents of final stage: List()
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3dc78904) from Actor[akka://sparkDriver/temp/$e]
[actor] handled message (0.125571 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3dc78904) from Actor[akka://sparkDriver/temp/$e]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f76f151) from Actor[akka://sparkDriver/temp/$f]
[actor] handled message (0.090296 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@f76f151) from Actor[akka://sparkDriver/temp/$f]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@49dd04c5) from Actor[akka://sparkDriver/temp/$g]
[actor] handled message (0.088749 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@49dd04c5) from Actor[akka://sparkDriver/temp/$g]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4d644765) from Actor[akka://sparkDriver/temp/$h]
[actor] handled message (0.089809 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@4d644765) from Actor[akka://sparkDriver/temp/$h]
Missing parents: List()
submitStage(Stage 0)
missing: List()
Submitting Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68), which has no missing parents
submitMissingTasks(Stage 0)
ensureFreeSpace(3120) called with curMem=176338, maxMem=3890007244
Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 3.6 GB)
Put block broadcast_1 locally took  1 ms
Putting block broadcast_1 without replication took  1 ms
ensureFreeSpace(1887) called with curMem=179458, maxMem=3890007244
Block broadcast_1_piece0 stored as bytes in memory (estimated size 1887.0 B, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Added broadcast_1_piece0 in memory on cluster01:39937 (size: 1887.0 B, free: 3.6 GB)
[actor] handled message (0.397814 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Put block broadcast_1_piece0 locally took  2 ms
Putting block broadcast_1_piece0 without replication took  2 ms
Submitting 1 missing tasks from Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68)
New pending tasks: Set(ResultTask(0, 0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (1.310259 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154144-0011/0 is now RUNNING
[actor] handled message (0.202225 ms) ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154144-0011/2 is now RUNNING
[actor] handled message (0.26407 ms) ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150124154144-0011/1 is now RUNNING
[actor] handled message (0.186902 ms) ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.408142 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.428458 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:60184/temp/$a]
[actor] handled message (0.034519 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:60184/temp/$a]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:37220] <- [akka.tcp://driverPropsFetcher@cluster03:60184] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.385212 ms) Disassociated [akka.tcp://sparkDriver@cluster01:37220] <- [akka.tcp://driverPropsFetcher@cluster03:60184] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:50339/temp/$a]
[actor] handled message (0.01491 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:50339/temp/$a]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:47242/temp/$a]
[actor] handled message (0.01489 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:47242/temp/$a]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:37220] <- [akka.tcp://driverPropsFetcher@cluster01:50339] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.011509 ms) Disassociated [akka.tcp://sparkDriver@cluster01:37220] <- [akka.tcp://driverPropsFetcher@cluster01:50339] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(2,cluster03:56728,2) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171] with ID 2
parentName: , name: TaskSet_0, runningTasks: 0
Valid locality levels for TaskSet 0.0: ANY
Starting task 0.0 in stage 0.0 (TID 0, cluster03, ANY, 1903 bytes)
[actor] handled message (43.244447 ms) RegisterExecutor(2,cluster03:56728,2) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:37220] <- [akka.tcp://driverPropsFetcher@cluster02:47242] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.022257 ms) Disassociated [akka.tcp://sparkDriver@cluster01:37220] <- [akka.tcp://driverPropsFetcher@cluster02:47242] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(1,cluster01:34679,2) from Actor[akka.tcp://sparkExecutor@cluster01:34679/user/Executor#-137507035]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster01:34679/user/Executor#-137507035] with ID 1
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (1.114224 ms) RegisterExecutor(1,cluster01:34679,2) from Actor[akka.tcp://sparkExecutor@cluster01:34679/user/Executor#-137507035]
[actor] received message RegisterExecutor(0,cluster02:58225,2) from Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256] with ID 0
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (2.75876 ms) RegisterExecutor(0,cluster02:58225,2) from Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256]
[actor] received message RegisterBlockManager(BlockManagerId(2, cluster03, 38739, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:37348/user/BlockManagerActor1#-885594463]) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$c]
Registering block manager cluster03:38739 with 3.1 GB RAM, BlockManagerId(2, cluster03, 38739, 0)
[actor] handled message (10.093075 ms) RegisterBlockManager(BlockManagerId(2, cluster03, 38739, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:37348/user/BlockManagerActor1#-885594463]) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$c]
[actor] received message RegisterBlockManager(BlockManagerId(1, cluster01, 59798, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:44720/user/BlockManagerActor1#1442535276]) from Actor[akka.tcp://sparkExecutor@cluster01:44720/temp/$c]
Registering block manager cluster01:59798 with 3.1 GB RAM, BlockManagerId(1, cluster01, 59798, 0)
[actor] handled message (0.588678 ms) RegisterBlockManager(BlockManagerId(1, cluster01, 59798, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:44720/user/BlockManagerActor1#1442535276]) from Actor[akka.tcp://sparkExecutor@cluster01:44720/temp/$c]
[actor] received message RegisterBlockManager(BlockManagerId(0, cluster02, 39325, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:38809/user/BlockManagerActor1#-2024822432]) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$c]
Registering block manager cluster02:39325 with 3.1 GB RAM, BlockManagerId(0, cluster02, 39325, 0)
[actor] handled message (0.596486 ms) RegisterBlockManager(BlockManagerId(0, cluster02, 39325, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:38809/user/BlockManagerActor1#-2024822432]) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$c]
[actor] received message StatusUpdate(2,0,RUNNING,org.apache.spark.util.SerializableBuffer@65614c46) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
[actor] handled message (0.543554 ms) StatusUpdate(2,0,RUNNING,org.apache.spark.util.SerializableBuffer@65614c46) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
[actor] received message GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$e]
[actor] handled message (0.149635 ms) GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$e]
Accepted connection from [cluster03/192.168.2.3:53769]
Selector selected 0 of 2 keys
Starting to receive [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Finished receiving [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,38739)] in 1 ms
Received [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Selector selected 0 of 2 keys
Handler thread delay is 0 ms
Handling [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Calling back
Handling message BufferMessage(id = 3, size = 48)
Handling as a buffer message BufferMessage(id = 3, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_1_piece0, level = null, data = null]
Converted block message array from buffer message in 0.003 s
Parsed as a block message array
Received [GetBlock(broadcast_1_piece0)]
GetBlock broadcast_1_piece0 started from 1422085307360
Getting local block broadcast_1_piece0 as bytes
Level for block broadcast_1_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_1_piece0 from memory
GetBlock broadcast_1_piece0 used  2 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Adding BlockMessage [type = 2, id = broadcast_1_piece0, level = null, data = 1887]
Added BufferMessage(id = 2, size = 1935)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Response to BufferMessage(id = 3, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster03,38739)] connectionid: cluster01_39937_2
Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster03,38739)]
Added [BufferAckMessage(aid = 3, id = 3, size = 1939)] to outbox for sending to [ConnectionManagerId(cluster03,38739)]
Selector selected 0 of 2 keys
Initiating connection to [cluster03/192.168.2.3:38739]
Selector selected 0 of 3 keys
Connected to [cluster03/192.168.2.3:38739], 1 messages pending
Selector selected 0 of 3 keys
Handling delay is 25 ms
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster03,38739)]
Finished sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster03,38739)] in 2 ms
[actor] received message UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$f]
Added broadcast_1_piece0 in memory on cluster03:38739 (size: 1887.0 B, free: 3.1 GB)
[actor] handled message (0.8846 ms) UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$f]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.649432 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$g]
[actor] handled message (0.0937 ms) GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$g]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Finished receiving [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster03,38739)] in 1 ms
Received [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Selector selected 0 of 3 keys
Handler thread delay is 1 ms
Handling [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Calling back
Handling message BufferMessage(id = 5, size = 48)
Handling as a buffer message BufferMessage(id = 5, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_0_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_0_piece0)]
GetBlock broadcast_0_piece0 started from 1422085307506
Getting local block broadcast_0_piece0 as bytes
Level for block broadcast_0_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_0_piece0 from memory
GetBlock broadcast_0_piece0 used  1 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Adding BlockMessage [type = 2, id = broadcast_0_piece0, level = null, data = 12633]
Added BufferMessage(id = 4, size = 12681)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Response to BufferMessage(id = 5, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster03,38739)] connectionid: cluster01_39937_2
Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster03,38739)]
Added [BufferAckMessage(aid = 5, id = 5, size = 12685)] to outbox for sending to [ConnectionManagerId(cluster03,38739)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Handling delay is 3 ms
Starting to send [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster03,38739)]
Finished sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster03,38739)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$h]
Added broadcast_0_piece0 in memory on cluster03:38739 (size: 12.3 KB, free: 3.1 GB)
[actor] handled message (1.179589 ms) UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$h]
[actor] received message GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$i]
[actor] handled message (0.037431 ms) GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$i]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (1.111945 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.557218 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (1.147481 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (1.23243 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.970822 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (1.297282 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),rdd_3_0,StorageLevel(false, true, false, true, 1),212376776,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$j]
Added rdd_3_0 in memory on cluster03:38739 (size: 202.5 MB, free: 2.9 GB)
[actor] handled message (0.353842 ms) UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),rdd_3_0,StorageLevel(false, true, false, true, 1),212376776,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$j]
[actor] received message StatusUpdate(2,0,FINISHED,org.apache.spark.util.SerializableBuffer@1267982e) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.956507 ms) StatusUpdate(2,0,FINISHED,org.apache.spark.util.SerializableBuffer@1267982e) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
Stage 0 (count at GraphLoader.scala:87) finished in 9.294 s
After removal of stage 0, remaining stages = 0
Job finished: count at GraphLoader.scala:87, took 9.363076155 s
Finished task 0.0 in stage 0.0 (TID 0) in 7545 ms on cluster03 (1/1)
It took 9864 ms to load the edges
Removed TaskSet 0.0, whose tasks have all completed, from pool 
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] handled message (0.230685 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
Starting job: reduce at VertexRDD.scala:111
Registering RDD 6 (mapPartitions at VertexRDD.scala:452)
Got job 1 (reduce at VertexRDD.scala:111) with 1 output partitions (allowLocal=false)
Final stage: Stage 1(reduce at VertexRDD.scala:111)
Parents of final stage: List(Stage 2)
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@79de41e4) from Actor[akka://sparkDriver/temp/$j]
[actor] handled message (0.098178 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@79de41e4) from Actor[akka://sparkDriver/temp/$j]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6eb81e3d) from Actor[akka://sparkDriver/temp/$k]
[actor] handled message (0.08504 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6eb81e3d) from Actor[akka://sparkDriver/temp/$k]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@79c96f94) from Actor[akka://sparkDriver/temp/$l]
[actor] handled message (0.075718 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@79c96f94) from Actor[akka://sparkDriver/temp/$l]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@17bc9c03) from Actor[akka://sparkDriver/temp/$m]
[actor] handled message (0.072061 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@17bc9c03) from Actor[akka://sparkDriver/temp/$m]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5fa69521) from Actor[akka://sparkDriver/temp/$n]
[actor] handled message (0.072379 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5fa69521) from Actor[akka://sparkDriver/temp/$n]
Missing parents: List(Stage 2)
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2978f7e2) from Actor[akka://sparkDriver/temp/$o]
[actor] handled message (0.064942 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2978f7e2) from Actor[akka://sparkDriver/temp/$o]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44da2bb3) from Actor[akka://sparkDriver/temp/$p]
[actor] handled message (0.095452 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@44da2bb3) from Actor[akka://sparkDriver/temp/$p]
missing: List()
Submitting Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452), which has no missing parents
submitMissingTasks(Stage 2)
ensureFreeSpace(3816) called with curMem=181345, maxMem=3890007244
Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 3.6 GB)
Put block broadcast_2 locally took  1 ms
Putting block broadcast_2 without replication took  1 ms
ensureFreeSpace(2263) called with curMem=185161, maxMem=3890007244
Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka://sparkDriver/temp/$q]
Added broadcast_2_piece0 in memory on cluster01:39937 (size: 2.2 KB, free: 3.6 GB)
[actor] handled message (0.382486 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka://sparkDriver/temp/$q]
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Put block broadcast_2_piece0 locally took  1 ms
Putting block broadcast_2_piece0 without replication took  2 ms
Submitting 1 missing tasks from Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452)
New pending tasks: Set(ShuffleMapTask(2, 0))
Adding task set 2.0 with 1 tasks
Epoch for TaskSet 2.0: 0
Valid locality levels for TaskSet 2.0: PROCESS_LOCAL, NODE_LOCAL, ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_2, runningTasks: 0
Starting task 0.0 in stage 2.0 (TID 1, cluster03, PROCESS_LOCAL, 1892 bytes)
[actor] handled message (1.494739 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
[actor] received message StatusUpdate(2,1,RUNNING,org.apache.spark.util.SerializableBuffer@4c28b3c3) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
[actor] handled message (0.041091 ms) StatusUpdate(2,1,RUNNING,org.apache.spark.util.SerializableBuffer@4c28b3c3) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
[actor] received message GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$k]
[actor] handled message (0.088535 ms) GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$k]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Finished receiving [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster03,38739)] in 0 ms
Received [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Selector selected 0 of 3 keys
Handler thread delay is 1 ms
Handling [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster03,38739)]
Calling back
Handling message BufferMessage(id = 7, size = 48)
Handling as a buffer message BufferMessage(id = 7, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_2_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_2_piece0)]
GetBlock broadcast_2_piece0 started from 1422085314499
Getting local block broadcast_2_piece0 as bytes
Level for block broadcast_2_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_2_piece0 from memory
GetBlock broadcast_2_piece0 used  0 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=2263 cap=2263]
Adding BlockMessage [type = 2, id = broadcast_2_piece0, level = null, data = 2263]
Added BufferMessage(id = 6, size = 2311)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=2263 cap=2263]
Response to BufferMessage(id = 7, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster03,38739)] connectionid: cluster01_39937_2
Sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster03,38739)]
Added [BufferAckMessage(aid = 7, id = 7, size = 2315)] to outbox for sending to [ConnectionManagerId(cluster03,38739)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster03,38739)]
Handling delay is 3 ms
Selector selected 0 of 3 keys
Finished sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster03,38739)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$l]
Added broadcast_2_piece0 in memory on cluster03:38739 (size: 2.2 KB, free: 2.9 GB)
[actor] handled message (0.391428 ms) UpdateBlockInfo(BlockManagerId(2, cluster03, 38739, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:37348/temp/$l]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_2, runningTasks: 1
[actor] handled message (0.663669 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message StatusUpdate(2,1,FINISHED,org.apache.spark.util.SerializableBuffer@441f79bf) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
parentName: , name: TaskSet_2, runningTasks: 0
[actor] handled message (0.62816 ms) StatusUpdate(2,1,FINISHED,org.apache.spark.util.SerializableBuffer@441f79bf) from Actor[akka.tcp://sparkExecutor@cluster03:56728/user/Executor#1892961171]
ShuffleMapTask finished on 2
Stage 2 (mapPartitions at VertexRDD.scala:452) finished in 1.638 s
looking for newly runnable stages
Finished task 0.0 in stage 2.0 (TID 1) in 1638 ms on cluster03 (1/1)
Removed TaskSet 2.0, whose tasks have all completed, from pool 
running: Set()
waiting: Set(Stage 1)
failed: Set()
Increasing epoch to 1
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@75cdd90a) from Actor[akka://sparkDriver/temp/$r]
[actor] handled message (0.107582 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@75cdd90a) from Actor[akka://sparkDriver/temp/$r]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1d645bf2) from Actor[akka://sparkDriver/temp/$s]
[actor] handled message (0.088186 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1d645bf2) from Actor[akka://sparkDriver/temp/$s]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27d07bf1) from Actor[akka://sparkDriver/temp/$t]
[actor] handled message (0.088239 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@27d07bf1) from Actor[akka://sparkDriver/temp/$t]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68791fa2) from Actor[akka://sparkDriver/temp/$u]
[actor] handled message (0.086255 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@68791fa2) from Actor[akka://sparkDriver/temp/$u]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@680bfa43) from Actor[akka://sparkDriver/temp/$v]
[actor] handled message (0.094553 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@680bfa43) from Actor[akka://sparkDriver/temp/$v]
Missing parents for Stage 1: List()
Submitting Stage 1 (MappedRDD[27] at map at VertexRDD.scala:111), which is now runnable
submitMissingTasks(Stage 1)
ensureFreeSpace(4168) called with curMem=187424, maxMem=3890007244
Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 3.6 GB)
Put block broadcast_3 locally took  1 ms
Putting block broadcast_3 without replication took  1 ms
ensureFreeSpace(2251) called with curMem=191592, maxMem=3890007244
Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka://sparkDriver/temp/$w]
Added broadcast_3_piece0 in memory on cluster01:39937 (size: 2.2 KB, free: 3.6 GB)
Updated info of block broadcast_3_piece0
Told master about block broadcast_3_piece0
Put block broadcast_3_piece0 locally took  2 ms
[actor] handled message (0.731824 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 39937, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka://sparkDriver/temp/$w]
Putting block broadcast_3_piece0 without replication took  4 ms
Submitting 1 missing tasks from Stage 1 (MappedRDD[27] at map at VertexRDD.scala:111)
New pending tasks: Set(ResultTask(1, 0))
Adding task set 1.0 with 1 tasks
Epoch for TaskSet 1.0: 1
Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_1, runningTasks: 0
Starting task 0.0 in stage 1.0 (TID 2, cluster02, PROCESS_LOCAL, 1055 bytes)
[actor] handled message (1.228905 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message StatusUpdate(0,2,RUNNING,org.apache.spark.util.SerializableBuffer@71cabde3) from Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256]
[actor] handled message (0.040169 ms) StatusUpdate(0,2,RUNNING,org.apache.spark.util.SerializableBuffer@71cabde3) from Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256]
[actor] received message GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$e]
[actor] handled message (0.182877 ms) GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$e]
Accepted connection from [cluster02/192.168.2.2:60131]
Starting to receive [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,39325)]
Finished receiving [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,39325)] in 0 ms
Received [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,39325)]
Selector selected 0 of 4 keys
Selector selected 0 of 4 keys
Handler thread delay is 0 ms
Handling [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,39325)]
Calling back
Handling message BufferMessage(id = 3, size = 48)
Handling as a buffer message BufferMessage(id = 3, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_3_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_3_piece0)]
GetBlock broadcast_3_piece0 started from 1422085316227
Getting local block broadcast_3_piece0 as bytes
Level for block broadcast_3_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_3_piece0 from memory
GetBlock broadcast_3_piece0 used  0 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=2251 cap=2251]
Adding BlockMessage [type = 2, id = broadcast_3_piece0, level = null, data = 2251]
Added BufferMessage(id = 8, size = 2299)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=2251 cap=2251]
Response to BufferMessage(id = 3, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,39325)] connectionid: cluster01_39937_4
Sending [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,39325)]
Added [BufferAckMessage(aid = 3, id = 9, size = 2303)] to outbox for sending to [ConnectionManagerId(cluster02,39325)]
Handling delay is 2 ms
Selector selected 0 of 4 keys
Initiating connection to [cluster02/192.168.2.2:39325]
Selector selected 0 of 5 keys
Connected to [cluster02/192.168.2.2:39325], 1 messages pending
Selector selected 0 of 5 keys
Selector selected 0 of 5 keys
Starting to send [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,39325)]
Finished sending [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster02,39325)] in 0 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 39325, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$f]
Added broadcast_3_piece0 in memory on cluster02:39325 (size: 2.2 KB, free: 3.1 GB)
[actor] handled message (0.409762 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 39325, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$f]
[actor] received message GetLocations(rdd_9_0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$g]
[actor] handled message (0.040057 ms) GetLocations(rdd_9_0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$g]
[actor] received message GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$h]
Asked to send map output locations for shuffle 0 to sparkExecutor@cluster02:38809
Size of output statuses for shuffle 0 is 127 bytes
[actor] handled message (2.683145 ms) GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$h]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
parentName: , name: TaskSet_1, runningTasks: 1
[actor] handled message (0.605861 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#-978117101]
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 39325, 0),rdd_9_0,StorageLevel(false, true, false, true, 1),67069400,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$i]
Added rdd_9_0 in memory on cluster02:39325 (size: 64.0 MB, free: 3.0 GB)
[actor] handled message (0.717188 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 39325, 0),rdd_9_0,StorageLevel(false, true, false, true, 1),67069400,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:38809/temp/$i]
[actor] received message StatusUpdate(0,2,FINISHED,org.apache.spark.util.SerializableBuffer@655d88b6) from Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256]
parentName: , name: TaskSet_1, runningTasks: 0
[actor] handled message (0.594633 ms) StatusUpdate(0,2,FINISHED,org.apache.spark.util.SerializableBuffer@655d88b6) from Actor[akka.tcp://sparkExecutor@cluster02:58225/user/Executor#-2090542256]
Stage 1 (reduce at VertexRDD.scala:111) finished in 1.138 s
After removal of stage 2, remaining stages = 1
After removal of stage 1, remaining stages = 0
Job finished: reduce at VertexRDD.scala:111, took 2.809638255 s
Finished task 0.0 in stage 1.0 (TID 2) in 1137 ms on cluster02 (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
Shutdown hook called
Changing view acls to: renq
Changing modify acls to: renq
SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(renq); users with modify permissions: Set(renq)
In createActorSystem, requireCookie is: off
Slf4jLogger started
Starting remoting
Remoting started; listening on addresses :[akka.tcp://sparkDriver@cluster01:40555]
Remoting now listens on addresses: [akka.tcp://sparkDriver@cluster01:40555]
Successfully started service 'sparkDriver' on port 40555.
Using serializer: class org.apache.spark.serializer.JavaSerializer
Registering MapOutputTracker
Registering BlockManagerMaster
[actor] received message ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#2073341199]
[actor] handled message (1.382354 ms) ExpireDeadHosts from Actor[akka://sparkDriver/user/BlockManagerMaster#2073341199]
Getting/creating local root dirs at '/tmp'
Created local directory at /tmp/spark-local-20150125142028-c030
Using SLF4J as the default logging framework
-Dio.netty.leakDetectionLevel: simple
java.nio.Buffer.address: available
sun.misc.Unsafe.theUnsafe: available
sun.misc.Unsafe.copyMemory: available
java.nio.Bits.unaligned: true
UID: 1002
Java version: 7
-Dio.netty.noUnsafe: false
sun.misc.Unsafe: available
-Dio.netty.noJavassist: false
Javassist: unavailable
You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
-Dio.netty.tmpdir: /tmp (java.io.tmpdir)
-Dio.netty.bitMode: 64 (sun.arch.data.model)
-Dio.netty.noPreferDirect: false
Successfully started service 'Connection manager for block manager' on port 51931.
Bound socket to port 51931 with id = ConnectionManagerId(cluster01,51931)
MemoryStore started with capacity 3.6 GB
Trying to register BlockManager
[actor] received message RegisterBlockManager(BlockManagerId(<driver>, cluster01, 51931, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-1032283580]) from Actor[akka://sparkDriver/temp/$a]
Registering block manager cluster01:51931 with 3.6 GB RAM, BlockManagerId(<driver>, cluster01, 51931, 0)
[actor] handled message (3.933321 ms) RegisterBlockManager(BlockManagerId(<driver>, cluster01, 51931, 0),3890007244,Actor[akka://sparkDriver/user/BlockManagerActor1#-1032283580]) from Actor[akka://sparkDriver/temp/$a]
Registered BlockManager
HTTP File server directory is /tmp/spark-5c5ffbb1-90c5-4554-8fd5-e1df0e142e76
Starting HTTP Server
HttpServer is not using security
Successfully started service 'HTTP file server' on port 53795.
HTTP file server started at: http://192.168.2.1:53795
Successfully started service 'SparkUI' on port 4040.
Started SparkUI at http://cluster01:4040
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of successful kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[Rate of failed kerberos logins and latency (milliseconds)], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(value=[GetGroups], about=, valueName=Time, type=DEFAULT, always=false, sampleName=Ops)
UgiMetrics, User and group related metrics
Kerberos krb5 configuration not found, setting default realm to empty
 Creating new Groups object
Trying to load the custom-built native-hadoop library...
Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib
Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Falling back to shell based
Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:265)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:290)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.security.Groups.parseStaticMapping(Groups.java:93)
	at org.apache.hadoop.security.Groups.<init>(Groups.java:77)
	at org.apache.hadoop.security.Groups.getUserToGroupsMappingService(Groups.java:240)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:255)
	at org.apache.hadoop.security.UserGroupInformation.setConfiguration(UserGroupInformation.java:283)
	at org.apache.spark.deploy.SparkHadoopUtil.<init>(SparkHadoopUtil.scala:36)
	at org.apache.spark.deploy.SparkHadoopUtil$.<init>(SparkHadoopUtil.scala:109)
	at org.apache.spark.deploy.SparkHadoopUtil$.<clinit>(SparkHadoopUtil.scala)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:238)
	at Toughness$.main(toughness.scala:12)
	at Toughness.main(toughness.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.apache.spark.deploy.SparkSubmit$.launch(SparkSubmit.scala:329)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:75)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
setsid exited with exit code 0
Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
Added JAR file:/home/renq/k-tough/target/scala-2.10/toughness_2.10-1.0.jar at http://192.168.2.1:53795/jars/toughness_2.10-1.0.jar with timestamp 1422166829105
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] handled message (6.115886 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
Connecting to master spark://cluster01:7077...
SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
[actor] received message RegisteredApplication(app-20150125142029-0014,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Connected to Spark cluster with app ID app-20150125142029-0014
[actor] handled message (2.614968 ms) RegisteredApplication(app-20150125142029-0014,spark://cluster01:7077) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150125142029-0014/0 on worker-20150121184032-cluster02-48233 (cluster02:48233) with 2 cores
Granted executor ID app-20150125142029-0014/0 on hostPort cluster02:48233 with 2 cores, 6.0 GB RAM
[actor] handled message (1.616351 ms) ExecutorAdded(0,worker-20150121184032-cluster02-48233,cluster02:48233,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150125142029-0014/1 on worker-20150121184029-cluster01-58596 (cluster01:58596) with 2 cores
Granted executor ID app-20150125142029-0014/1 on hostPort cluster01:58596 with 2 cores, 6.0 GB RAM
[actor] handled message (0.498214 ms) ExecutorAdded(1,worker-20150121184029-cluster01-58596,cluster01:58596,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor added: app-20150125142029-0014/2 on worker-20150121184032-cluster03-48380 (cluster03:48380) with 2 cores
Granted executor ID app-20150125142029-0014/2 on hostPort cluster03:48380 with 2 cores, 6.0 GB RAM
[actor] handled message (0.451496 ms) ExecutorAdded(2,worker-20150121184032-cluster03-48380,cluster03:48380,2,6144) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150125142029-0014/1 is now LOADING
[actor] handled message (0.956556 ms) ExecutorUpdated(1,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150125142029-0014/0 is now LOADING
[actor] handled message (0.138394 ms) ExecutorUpdated(0,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150125142029-0014/2 is now LOADING
[actor] handled message (0.143487 ms) ExecutorUpdated(2,LOADING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
ensureFreeSpace(163705) called with curMem=0, maxMem=3890007244
Block broadcast_0 stored as values in memory (estimated size 159.9 KB, free 3.6 GB)
Put block broadcast_0 locally took  194 ms
Putting block broadcast_0 without replication took  194 ms
ensureFreeSpace(12633) called with curMem=163705, maxMem=3890007244
Block broadcast_0_piece0 stored as bytes in memory (estimated size 12.3 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Added broadcast_0_piece0 in memory on cluster01:51931 (size: 12.3 KB, free: 3.6 GB)
[actor] handled message (1.093664 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka://sparkDriver/temp/$b]
Updated info of block broadcast_0_piece0
Told master about block broadcast_0_piece0
Put block broadcast_0_piece0 locally took  12 ms
Putting block broadcast_0_piece0 without replication took  14 ms
Creating new JobConf and caching it for later re-use
hadoop login
hadoop login commit
using local user:UnixPrincipal: renq
UGI loginUser:renq (auth:SIMPLE)
Time taken to get FileStatuses: 4
Total input paths to process : 1
Total # of splits generated by getSplits: 3, TimeTaken: 9
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6bddea9) from Actor[akka://sparkDriver/temp/$c]
[actor] handled message (0.412459 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6bddea9) from Actor[akka://sparkDriver/temp/$c]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ddc63f6) from Actor[akka://sparkDriver/temp/$d]
[actor] handled message (0.126298 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@2ddc63f6) from Actor[akka://sparkDriver/temp/$d]
Starting job: count at GraphLoader.scala:87
Got job 0 (count at GraphLoader.scala:87) with 1 output partitions (allowLocal=false)
Final stage: Stage 0(count at GraphLoader.scala:87)
Parents of final stage: List()
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1657dc89) from Actor[akka://sparkDriver/temp/$e]
[actor] handled message (0.143849 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1657dc89) from Actor[akka://sparkDriver/temp/$e]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@728b5f94) from Actor[akka://sparkDriver/temp/$f]
[actor] handled message (0.170793 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@728b5f94) from Actor[akka://sparkDriver/temp/$f]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1c30284c) from Actor[akka://sparkDriver/temp/$g]
[actor] handled message (0.142579 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1c30284c) from Actor[akka://sparkDriver/temp/$g]
[actor] received message ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1da5a409) from Actor[akka://sparkDriver/temp/$h]
Executor updated: app-20150125142029-0014/2 is now RUNNING
[actor] handled message (0.220881 ms) ExecutorUpdated(2,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] handled message (0.132274 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@1da5a409) from Actor[akka://sparkDriver/temp/$h]
[actor] received message ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150125142029-0014/0 is now RUNNING
Missing parents: List()
[actor] handled message (0.175525 ms) ExecutorUpdated(0,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
submitStage(Stage 0)
missing: List()
Submitting Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68), which has no missing parents
submitMissingTasks(Stage 0)
ensureFreeSpace(3120) called with curMem=176338, maxMem=3890007244
Block broadcast_1 stored as values in memory (estimated size 3.0 KB, free 3.6 GB)
Put block broadcast_1 locally took  1 ms
Putting block broadcast_1 without replication took  1 ms
ensureFreeSpace(1887) called with curMem=179458, maxMem=3890007244
Block broadcast_1_piece0 stored as bytes in memory (estimated size 1887.0 B, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Added broadcast_1_piece0 in memory on cluster01:51931 (size: 1887.0 B, free: 3.6 GB)
Updated info of block broadcast_1_piece0
Told master about block broadcast_1_piece0
Put block broadcast_1_piece0 locally took  1 ms
[actor] handled message (0.437095 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka://sparkDriver/temp/$i]
Putting block broadcast_1_piece0 without replication took  1 ms
Submitting 1 missing tasks from Stage 0 (GraphLoader.edgeListFile - edges (/home/hadoop/data/roadNet-CA.txt) MapPartitionsRDD[3] at mapPartitionsWithIndex at GraphLoader.scala:68)
New pending tasks: Set(ResultTask(0, 0))
Adding task set 0.0 with 1 tasks
Epoch for TaskSet 0.0: 0
Valid locality levels for TaskSet 0.0: ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (1.252332 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
Executor updated: app-20150125142029-0014/1 is now RUNNING
[actor] handled message (0.292499 ms) ExecutorUpdated(1,RUNNING,None,None) from Actor[akka.tcp://sparkMaster@cluster01:7077/user/Master#-1182251110]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.558577 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (0.421772 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:59212/temp/$a]
[actor] handled message (0.036126 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster02:59212/temp/$a]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:48092/temp/$a]
[actor] handled message (0.024202 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster03:48092/temp/$a]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:40555] <- [akka.tcp://driverPropsFetcher@cluster03:48092] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.396001 ms) Disassociated [akka.tcp://sparkDriver@cluster01:40555] <- [akka.tcp://driverPropsFetcher@cluster03:48092] from Actor[akka://sparkDriver/deadLetters]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:40555] <- [akka.tcp://driverPropsFetcher@cluster02:59212] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.014324 ms) Disassociated [akka.tcp://sparkDriver@cluster01:40555] <- [akka.tcp://driverPropsFetcher@cluster02:59212] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(0,cluster02:54148,2) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052] with ID 0
parentName: , name: TaskSet_0, runningTasks: 0
Valid locality levels for TaskSet 0.0: ANY
Starting task 0.0 in stage 0.0 (TID 0, cluster02, ANY, 1903 bytes)
[actor] handled message (23.24992 ms) RegisterExecutor(0,cluster02:54148,2) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
[actor] received message RegisterExecutor(2,cluster03:59469,2) from Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244] with ID 2
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (1.237725 ms) RegisterExecutor(2,cluster03:59469,2) from Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244]
[actor] received message RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:38232/temp/$a]
[actor] handled message (0.018843 ms) RetrieveSparkProps from Actor[akka.tcp://driverPropsFetcher@cluster01:38232/temp/$a]
[actor] received message RegisterBlockManager(BlockManagerId(0, cluster02, 37364, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:48386/user/BlockManagerActor1#-1523174234]) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$c]
Registering block manager cluster02:37364 with 3.1 GB RAM, BlockManagerId(0, cluster02, 37364, 0)
[actor] handled message (0.363996 ms) RegisterBlockManager(BlockManagerId(0, cluster02, 37364, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster02:48386/user/BlockManagerActor1#-1523174234]) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$c]
[actor] received message RegisterBlockManager(BlockManagerId(2, cluster03, 45565, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:33301/user/BlockManagerActor1#-1028024171]) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$c]
Registering block manager cluster03:45565 with 3.1 GB RAM, BlockManagerId(2, cluster03, 45565, 0)
[actor] handled message (0.334743 ms) RegisterBlockManager(BlockManagerId(2, cluster03, 45565, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster03:33301/user/BlockManagerActor1#-1028024171]) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$c]
[actor] received message Disassociated [akka.tcp://sparkDriver@cluster01:40555] <- [akka.tcp://driverPropsFetcher@cluster01:38232] from Actor[akka://sparkDriver/deadLetters]
[actor] handled message (0.024615 ms) Disassociated [akka.tcp://sparkDriver@cluster01:40555] <- [akka.tcp://driverPropsFetcher@cluster01:38232] from Actor[akka://sparkDriver/deadLetters]
[actor] received message RegisterExecutor(1,cluster01:51610,2) from Actor[akka.tcp://sparkExecutor@cluster01:51610/user/Executor#-341001754]
Registered executor: Actor[akka.tcp://sparkExecutor@cluster01:51610/user/Executor#-341001754] with ID 1
parentName: , name: TaskSet_0, runningTasks: 1
Valid locality levels for TaskSet 0.0: ANY
[actor] handled message (0.811114 ms) RegisterExecutor(1,cluster01:51610,2) from Actor[akka.tcp://sparkExecutor@cluster01:51610/user/Executor#-341001754]
[actor] received message StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@41737f25) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
[actor] handled message (0.635682 ms) StatusUpdate(0,0,RUNNING,org.apache.spark.util.SerializableBuffer@41737f25) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
[actor] received message GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$e]
[actor] handled message (0.883169 ms) GetLocations(broadcast_1_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$e]
Accepted connection from [cluster02/192.168.2.2:47453]
Selector selected 0 of 2 keys
Starting to receive [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Finished receiving [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,37364)] in 1 ms
Received [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Handler thread delay is 1 ms
Handling [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Calling back
Handling message BufferMessage(id = 3, size = 48)
Handling as a buffer message BufferMessage(id = 3, size = 48)
Selector selected 0 of 2 keys
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_1_piece0, level = null, data = null]
Converted block message array from buffer message in 0.01 s
Parsed as a block message array
Received [GetBlock(broadcast_1_piece0)]
GetBlock broadcast_1_piece0 started from 1422166831976
Getting local block broadcast_1_piece0 as bytes
Level for block broadcast_1_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_1_piece0 from memory
GetBlock broadcast_1_piece0 used  2 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Adding BlockMessage [type = 2, id = broadcast_1_piece0, level = null, data = 1887]
Added BufferMessage(id = 2, size = 1935)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=1887 cap=1887]
Response to BufferMessage(id = 3, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,37364)] connectionid: cluster01_51931_2
Sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,37364)]
Added [BufferAckMessage(aid = 3, id = 3, size = 1939)] to outbox for sending to [ConnectionManagerId(cluster02,37364)]
Selector selected 0 of 2 keys
Handling delay is 26 ms
Initiating connection to [cluster02/192.168.2.2:37364]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Connected to [cluster02/192.168.2.2:37364], 1 messages pending
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,37364)]
Finished sending [BufferAckMessage(aid = 3, id = 3, size = 1939)] to [ConnectionManagerId(cluster02,37364)] in 2 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$f]
Added broadcast_1_piece0 in memory on cluster02:37364 (size: 1887.0 B, free: 3.1 GB)
[actor] handled message (0.403077 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),1887,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$f]
[actor] received message RegisterBlockManager(BlockManagerId(1, cluster01, 61000, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:57618/user/BlockManagerActor1#-1145617597]) from Actor[akka.tcp://sparkExecutor@cluster01:57618/temp/$c]
Registering block manager cluster01:61000 with 3.1 GB RAM, BlockManagerId(1, cluster01, 61000, 0)
[actor] handled message (0.372654 ms) RegisterBlockManager(BlockManagerId(1, cluster01, 61000, 0),3333968363,Actor[akka.tcp://sparkExecutor@cluster01:57618/user/BlockManagerActor1#-1145617597]) from Actor[akka.tcp://sparkExecutor@cluster01:57618/temp/$c]
[actor] received message GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$g]
[actor] handled message (0.096206 ms) GetLocations(broadcast_0_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$g]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Finished receiving [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,37364)] in 0 ms
Received [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Handler thread delay is 1 ms
Handling [BufferMessage(id = 5, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Calling back
Handling message BufferMessage(id = 5, size = 48)
Handling as a buffer message BufferMessage(id = 5, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_0_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_0_piece0)]
Selector selected 0 of 3 keys
GetBlock broadcast_0_piece0 started from 1422166832119
Getting local block broadcast_0_piece0 as bytes
Level for block broadcast_0_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_0_piece0 from memory
GetBlock broadcast_0_piece0 used  1 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Adding BlockMessage [type = 2, id = broadcast_0_piece0, level = null, data = 12633]
Added BufferMessage(id = 4, size = 12681)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=12633 cap=12633]
Response to BufferMessage(id = 5, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,37364)] connectionid: cluster01_51931_2
Sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,37364)]
Added [BufferAckMessage(aid = 5, id = 5, size = 12685)] to outbox for sending to [ConnectionManagerId(cluster02,37364)]
Handling delay is 3 ms
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,37364)]
Finished sending [BufferAckMessage(aid = 5, id = 5, size = 12685)] to [ConnectionManagerId(cluster02,37364)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$h]
Added broadcast_0_piece0 in memory on cluster02:37364 (size: 12.3 KB, free: 3.1 GB)
[actor] handled message (0.431074 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),12633,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$h]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.638746 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$i]
[actor] handled message (0.057923 ms) GetLocations(rdd_3_0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$i]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.882832 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.60082 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.586156 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.561281 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.611086 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_0, runningTasks: 1
[actor] handled message (0.551872 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),rdd_3_0,StorageLevel(false, true, false, true, 1),212376776,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$j]
Added rdd_3_0 in memory on cluster02:37364 (size: 202.5 MB, free: 2.9 GB)
[actor] handled message (0.748126 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),rdd_3_0,StorageLevel(false, true, false, true, 1),212376776,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$j]
[actor] received message StatusUpdate(0,0,FINISHED,org.apache.spark.util.SerializableBuffer@62a3ab9b) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
parentName: , name: TaskSet_0, runningTasks: 0
[actor] handled message (2.89944 ms) StatusUpdate(0,0,FINISHED,org.apache.spark.util.SerializableBuffer@62a3ab9b) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
Stage 0 (count at GraphLoader.scala:87) finished in 9.015 s
Finished task 0.0 in stage 0.0 (TID 0) in 7429 ms on cluster02 (1/1)
Removed TaskSet 0.0, whose tasks have all completed, from pool 
After removal of stage 0, remaining stages = 0
Job finished: count at GraphLoader.scala:87, took 9.095333223 s
It took 9668 ms to load the edges
Starting job: reduce at VertexRDD.scala:111
Registering RDD 6 (mapPartitions at VertexRDD.scala:452)
Got job 1 (reduce at VertexRDD.scala:111) with 1 output partitions (allowLocal=false)
Final stage: Stage 1(reduce at VertexRDD.scala:111)
Parents of final stage: List(Stage 2)
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5bacfb2d) from Actor[akka://sparkDriver/temp/$j]
[actor] handled message (0.087524 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@5bacfb2d) from Actor[akka://sparkDriver/temp/$j]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@399e7660) from Actor[akka://sparkDriver/temp/$k]
[actor] handled message (0.061809 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@399e7660) from Actor[akka://sparkDriver/temp/$k]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@526db62d) from Actor[akka://sparkDriver/temp/$l]
[actor] handled message (0.107173 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@526db62d) from Actor[akka://sparkDriver/temp/$l]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@20d36ea2) from Actor[akka://sparkDriver/temp/$m]
[actor] handled message (0.059604 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@20d36ea2) from Actor[akka://sparkDriver/temp/$m]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@19045e84) from Actor[akka://sparkDriver/temp/$n]
[actor] handled message (0.058787 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@19045e84) from Actor[akka://sparkDriver/temp/$n]
Missing parents: List(Stage 2)
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@86064c8) from Actor[akka://sparkDriver/temp/$o]
[actor] handled message (0.066824 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@86064c8) from Actor[akka://sparkDriver/temp/$o]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@70788ac3) from Actor[akka://sparkDriver/temp/$p]
[actor] handled message (0.091336 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@70788ac3) from Actor[akka://sparkDriver/temp/$p]
missing: List()
Submitting Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452), which has no missing parents
submitMissingTasks(Stage 2)
ensureFreeSpace(3816) called with curMem=181345, maxMem=3890007244
Block broadcast_2 stored as values in memory (estimated size 3.7 KB, free 3.6 GB)
Put block broadcast_2 locally took  1 ms
Putting block broadcast_2 without replication took  1 ms
ensureFreeSpace(2263) called with curMem=185161, maxMem=3890007244
Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.2 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka://sparkDriver/temp/$q]
Added broadcast_2_piece0 in memory on cluster01:51931 (size: 2.2 KB, free: 3.6 GB)
[actor] handled message (0.405299 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka://sparkDriver/temp/$q]
Updated info of block broadcast_2_piece0
Told master about block broadcast_2_piece0
Put block broadcast_2_piece0 locally took  1 ms
Putting block broadcast_2_piece0 without replication took  1 ms
Submitting 1 missing tasks from Stage 2 (VertexRDD.createRoutingTables - vid2pid (aggregation) MapPartitionsRDD[6] at mapPartitions at VertexRDD.scala:452)
New pending tasks: Set(ShuffleMapTask(2, 0))
Adding task set 2.0 with 1 tasks
Epoch for TaskSet 2.0: 0
Valid locality levels for TaskSet 2.0: PROCESS_LOCAL, NODE_LOCAL, ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_2, runningTasks: 0
Starting task 0.0 in stage 2.0 (TID 1, cluster02, PROCESS_LOCAL, 1892 bytes)
[actor] handled message (1.518032 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
submitStage(Stage 1)
missing: List(Stage 2)
submitStage(Stage 2)
[actor] received message StatusUpdate(0,1,RUNNING,org.apache.spark.util.SerializableBuffer@60b489d2) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
[actor] handled message (0.043883 ms) StatusUpdate(0,1,RUNNING,org.apache.spark.util.SerializableBuffer@60b489d2) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
[actor] received message GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$k]
[actor] handled message (0.083653 ms) GetLocations(broadcast_2_piece0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$k]
Selector selected 0 of 3 keys
Starting to receive [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Finished receiving [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,37364)] in 0 ms
Received [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Selector selected 0 of 3 keys
Handler thread delay is 2 ms
Handling [BufferMessage(id = 7, size = 48)] from [ConnectionManagerId(cluster02,37364)]
Calling back
Handling message BufferMessage(id = 7, size = 48)
Handling as a buffer message BufferMessage(id = 7, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_2_piece0, level = null, data = null]
Converted block message array from buffer message in 0.0 s
Parsed as a block message array
Received [GetBlock(broadcast_2_piece0)]
GetBlock broadcast_2_piece0 started from 1422166839021
Getting local block broadcast_2_piece0 as bytes
Level for block broadcast_2_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_2_piece0 from memory
GetBlock broadcast_2_piece0 used  0 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=2263 cap=2263]
Adding BlockMessage [type = 2, id = broadcast_2_piece0, level = null, data = 2263]
Added BufferMessage(id = 6, size = 2311)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=2263 cap=2263]
Response to BufferMessage(id = 7, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,37364)] connectionid: cluster01_51931_2
Sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,37364)]
Added [BufferAckMessage(aid = 7, id = 7, size = 2315)] to outbox for sending to [ConnectionManagerId(cluster02,37364)]
Selector selected 0 of 3 keys
Selector selected 0 of 3 keys
Starting to send [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,37364)]
Selector selected 0 of 3 keys
Handling delay is 5 ms
Finished sending [BufferAckMessage(aid = 7, id = 7, size = 2315)] to [ConnectionManagerId(cluster02,37364)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$l]
Added broadcast_2_piece0 in memory on cluster02:37364 (size: 2.2 KB, free: 2.9 GB)
[actor] handled message (0.40013 ms) UpdateBlockInfo(BlockManagerId(0, cluster02, 37364, 0),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),2263,0,0) from Actor[akka.tcp://sparkExecutor@cluster02:48386/temp/$l]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_2, runningTasks: 1
[actor] handled message (0.667956 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_2, runningTasks: 1
[actor] handled message (0.674188 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message StatusUpdate(0,1,FINISHED,org.apache.spark.util.SerializableBuffer@12812bf7) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
parentName: , name: TaskSet_2, runningTasks: 0
[actor] handled message (1.297757 ms) StatusUpdate(0,1,FINISHED,org.apache.spark.util.SerializableBuffer@12812bf7) from Actor[akka.tcp://sparkExecutor@cluster02:54148/user/Executor#528973052]
ShuffleMapTask finished on 0
Stage 2 (mapPartitions at VertexRDD.scala:452) finished in 1.669 s
looking for newly runnable stages
Finished task 0.0 in stage 2.0 (TID 1) in 1669 ms on cluster02 (1/1)
Removed TaskSet 2.0, whose tasks have all completed, from pool 
running: Set()
waiting: Set(Stage 1)
failed: Set()
Increasing epoch to 1
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6303b6e9) from Actor[akka://sparkDriver/temp/$r]
[actor] handled message (0.109733 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@6303b6e9) from Actor[akka://sparkDriver/temp/$r]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@8ddadc8) from Actor[akka://sparkDriver/temp/$s]
[actor] handled message (0.150611 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@8ddadc8) from Actor[akka://sparkDriver/temp/$s]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@11bc2a04) from Actor[akka://sparkDriver/temp/$t]
[actor] handled message (0.140646 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@11bc2a04) from Actor[akka://sparkDriver/temp/$t]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@586a75b4) from Actor[akka://sparkDriver/temp/$u]
[actor] handled message (0.140697 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@586a75b4) from Actor[akka://sparkDriver/temp/$u]
[actor] received message GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3555a9c5) from Actor[akka://sparkDriver/temp/$v]
[actor] handled message (0.139724 ms) GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3555a9c5) from Actor[akka://sparkDriver/temp/$v]
Missing parents for Stage 1: List()
Submitting Stage 1 (MappedRDD[27] at map at VertexRDD.scala:111), which is now runnable
submitMissingTasks(Stage 1)
ensureFreeSpace(4168) called with curMem=187424, maxMem=3890007244
Block broadcast_3 stored as values in memory (estimated size 4.1 KB, free 3.6 GB)
Put block broadcast_3 locally took  1 ms
Putting block broadcast_3 without replication took  1 ms
ensureFreeSpace(2251) called with curMem=191592, maxMem=3890007244
Block broadcast_3_piece0 stored as bytes in memory (estimated size 2.2 KB, free 3.6 GB)
[actor] received message UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka://sparkDriver/temp/$w]
Added broadcast_3_piece0 in memory on cluster01:51931 (size: 2.2 KB, free: 3.6 GB)
[actor] handled message (0.378099 ms) UpdateBlockInfo(BlockManagerId(<driver>, cluster01, 51931, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka://sparkDriver/temp/$w]
Updated info of block broadcast_3_piece0
Told master about block broadcast_3_piece0
Put block broadcast_3_piece0 locally took  3 ms
Putting block broadcast_3_piece0 without replication took  3 ms
Submitting 1 missing tasks from Stage 1 (MappedRDD[27] at map at VertexRDD.scala:111)
New pending tasks: Set(ResultTask(1, 0))
Adding task set 1.0 with 1 tasks
Epoch for TaskSet 1.0: 1
Valid locality levels for TaskSet 1.0: NO_PREF, ANY
[actor] received message ReviveOffers from Actor[akka://sparkDriver/deadLetters]
parentName: , name: TaskSet_1, runningTasks: 0
Starting task 0.0 in stage 1.0 (TID 2, cluster03, PROCESS_LOCAL, 1055 bytes)
[actor] handled message (1.241272 ms) ReviveOffers from Actor[akka://sparkDriver/deadLetters]
[actor] received message StatusUpdate(2,2,RUNNING,org.apache.spark.util.SerializableBuffer@2518b78d) from Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244]
[actor] handled message (0.042377 ms) StatusUpdate(2,2,RUNNING,org.apache.spark.util.SerializableBuffer@2518b78d) from Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244]
[actor] received message GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$e]
[actor] handled message (0.183852 ms) GetLocations(broadcast_3_piece0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$e]
Accepted connection from [cluster03/192.168.2.3:39073]
Selector selected 0 of 4 keys
Starting to receive [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,45565)]
Finished receiving [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,45565)] in 0 ms
Received [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,45565)]
Selector selected 0 of 4 keys
Handler thread delay is 2 ms
Handling [BufferMessage(id = 3, size = 48)] from [ConnectionManagerId(cluster03,45565)]
Calling back
Handling message BufferMessage(id = 3, size = 48)
Handling as a buffer message BufferMessage(id = 3, size = 48)
Creating block message of size 44 bytes
Trying to convert buffer java.nio.HeapByteBuffer[pos=0 lim=44 cap=44] to block message
Created BlockMessage [type = 1, id = broadcast_3_piece0, level = null, data = null]
Converted block message array from buffer message in 0.001 s
Parsed as a block message array
Received [GetBlock(broadcast_3_piece0)]
GetBlock broadcast_3_piece0 started from 1422166840796
Getting local block broadcast_3_piece0 as bytes
Level for block broadcast_3_piece0 is StorageLevel(true, true, false, false, 1)
Getting block broadcast_3_piece0 from memory
GetBlock broadcast_3_piece0 used  1 ms and got buffer java.nio.HeapByteBuffer[pos=0 lim=2251 cap=2251]
Adding BlockMessage [type = 2, id = broadcast_3_piece0, level = null, data = 2251]
Added BufferMessage(id = 8, size = 2299)
Buffer list:
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=44 cap=44]
java.nio.HeapByteBuffer[pos=0 lim=4 cap=4]
java.nio.HeapByteBuffer[pos=0 lim=2251 cap=2251]
Response to BufferMessage(id = 3, size = 48) does not have ack id set
Before Sending [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster03,45565)] connectionid: cluster01_51931_4
Sending [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster03,45565)]
Added [BufferAckMessage(aid = 3, id = 9, size = 2303)] to outbox for sending to [ConnectionManagerId(cluster03,45565)]
Selector selected 0 of 4 keys
Initiating connection to [cluster03/192.168.2.3:45565]
Handling delay is 5 ms
Connected to [cluster03/192.168.2.3:45565], 1 messages pending
Selector selected 0 of 5 keys
Selector selected 0 of 5 keys
Starting to send [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster03,45565)]
Finished sending [BufferAckMessage(aid = 3, id = 9, size = 2303)] to [ConnectionManagerId(cluster03,45565)] in 1 ms
[actor] received message UpdateBlockInfo(BlockManagerId(2, cluster03, 45565, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$f]
Added broadcast_3_piece0 in memory on cluster03:45565 (size: 2.2 KB, free: 3.1 GB)
[actor] handled message (0.367782 ms) UpdateBlockInfo(BlockManagerId(2, cluster03, 45565, 0),broadcast_3_piece0,StorageLevel(false, true, false, false, 1),2251,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$f]
[actor] received message GetLocations(rdd_9_0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$g]
[actor] handled message (0.040047 ms) GetLocations(rdd_9_0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$g]
[actor] received message GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$h]
Asked to send map output locations for shuffle 0 to sparkExecutor@cluster03:33301
Size of output statuses for shuffle 0 is 127 bytes
[actor] handled message (2.677895 ms) GetMapOutputStatuses(0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$h]
[actor] received message ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
parentName: , name: TaskSet_1, runningTasks: 1
[actor] handled message (0.59893 ms) ReviveOffers from Actor[akka://sparkDriver/user/CoarseGrainedScheduler#1489977005]
[actor] received message UpdateBlockInfo(BlockManagerId(2, cluster03, 45565, 0),rdd_9_0,StorageLevel(false, true, false, true, 1),67069400,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$i]
Added rdd_9_0 in memory on cluster03:45565 (size: 64.0 MB, free: 3.0 GB)
[actor] handled message (0.706193 ms) UpdateBlockInfo(BlockManagerId(2, cluster03, 45565, 0),rdd_9_0,StorageLevel(false, true, false, true, 1),67069400,0,0) from Actor[akka.tcp://sparkExecutor@cluster03:33301/temp/$i]
[actor] received message StatusUpdate(2,2,FINISHED,org.apache.spark.util.SerializableBuffer@4f33addc) from Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244]
parentName: , name: TaskSet_1, runningTasks: 0
[actor] handled message (1.233367 ms) StatusUpdate(2,2,FINISHED,org.apache.spark.util.SerializableBuffer@4f33addc) from Actor[akka.tcp://sparkExecutor@cluster03:59469/user/Executor#691603244]
Stage 1 (reduce at VertexRDD.scala:111) finished in 1.175 s
After removal of stage 2, remaining stages = 1
After removal of stage 1, remaining stages = 0
Job finished: reduce at VertexRDD.scala:111, took 2.882786562 s
Finished task 0.0 in stage 1.0 (TID 2) in 1175 ms on cluster03 (1/1)
Removed TaskSet 1.0, whose tasks have all completed, from pool 
Shutdown hook called
